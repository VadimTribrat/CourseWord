{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_words(len_of_win):\n",
    "    expVectorData = []\n",
    "    for i, token in enumerate(words):\n",
    "        exampleVector = []\n",
    "        j = -1 * len_of_win\n",
    "        for _ in range(2*len_of_win+1):\n",
    "            try:\n",
    "                exampleVector.append(vectorData[i+j])\n",
    "            except Exception:\n",
    "                exampleVector.append([0 for i in range(27)])\n",
    "            j = j + 1\n",
    "        expVectorData.append(exampleVector)\n",
    "    new_tags = tags.copy()\n",
    "    for j, i in enumerate(new_tags):\n",
    "        if i == 'name' or i == 'surname':\n",
    "            new_tags[j] = 1\n",
    "        else:\n",
    "            new_tags[j] = 0\n",
    "            \n",
    "    new_expVectorData = []\n",
    "    for i in expVectorData:\n",
    "        temp = []\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                temp.append(k)\n",
    "        new_expVectorData.append(temp)\n",
    "    \n",
    "    print(len_of_win)\n",
    "\n",
    "    X = np.array(new_expVectorData)\n",
    "    y = np.array(new_tags)\n",
    "#    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "    sgd = SGDClassifier()\n",
    "#    sgd.fit(X_train, y_train)\n",
    "    return np.mean(cross_val_score(sgd, X, y, cv = 5, scoring = make_scorer(f1_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1a863fd08>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = []\n",
    "for i in range(1, 11):\n",
    "    temp.append(num_of_words(i))\n",
    "plt.plot( range(1, 11), temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 84696/84696 [01:57<00:00, 719.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7666314677930305"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "temp = []\n",
    "\n",
    "for word in tqdm(words):\n",
    "        if 'Name' in morph.parse(word)[0].tag:\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "            \n",
    "new_tags = tags.copy()\n",
    "for j, i in enumerate(new_tags):\n",
    "    if i == 'name' :\n",
    "        new_tags[j] = 1\n",
    "    else:\n",
    "        new_tags[j] = 0\n",
    "        \n",
    "f1_score(temp, new_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "os.chdir(r\"C:\\Users\\etrib\\Documents\\CourseWork\\Data\\testset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = glob.glob('*.txt')\n",
    "docslist = [i.split(sep = '.')[0] for i in docs]\n",
    "words = ['start_token']\n",
    "tags = ['start_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "req_tokens = ['loc_name', 'org_name', 'name', 'surname', 'org_descr', 'loc_descr']\n",
    "not_match = ['nickname', 'job', 'patronymic']\n",
    "\n",
    "for doc in [open(i + '.tokens', encoding = 'utf-8').read().split(sep = '\\n') for i in docslist]:\n",
    "    for k in doc:\n",
    "        k = k.split()\n",
    "        if k:\n",
    "            word = k[-1]\n",
    "            ids = k[0]\n",
    "            word_dict[ids] = [word] \n",
    "for doc in [open(i + '.spans', encoding = 'utf-8').read().split(sep = '\\n') for i in docslist]:\n",
    "    for k in doc:\n",
    "        k = k.split()\n",
    "        if k:\n",
    "            word = k[-1]\n",
    "            ids = k[-2]\n",
    "            tok = k[1]\n",
    "        if tok in req_tokens:\n",
    "            if (ids in word_dict) and word_dict[ids][0] == word:\n",
    "                word_dict[ids].append(tok)\n",
    "        if tok in not_match:\n",
    "            if (ids in word_dict) and word_dict[ids][0] == word:\n",
    "                word_dict[ids].append('others') \n",
    "for k in word_dict:\n",
    "    if len(word_dict[k]) != 2:\n",
    "        word_dict[k].append('not_ne')\n",
    "for k in word_dict:\n",
    "    words.append(word_dict[k][0])\n",
    "    tags.append(word_dict[k][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.append(\"end_token\")\n",
    "tags.append(\"end_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_state', 'name', 'not_ne', 'start_state', 'surname'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j, i in enumerate(tags):\n",
    "    if i!= 'name' and i!='surname' and i != 'start_state' and i!= 'end_state':\n",
    "        tags[j] = 'not_ne'\n",
    "set(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 90324/90324 [01:43<00:00, 869.00it/s]\n"
     ]
    }
   ],
   "source": [
    "wordslist = []\n",
    "taglist = []\n",
    "for i, word in enumerate(tqdm(words)):\n",
    "    if word in [\".\", \"!\", \"?\", \"«\", \"»\"]:\n",
    "        if word in [\".\", \"!\", \"?\"] and words[i+1] not in [\"«\", \"»\"]:\n",
    "            wordslist.append(\"end_token\")\n",
    "            taglist.append(\"end_state\")\n",
    "            wordslist.append(\"start_token\")\n",
    "            taglist.append(\"start_state\")\n",
    "        if word in [\"«\", \"»\"]:\n",
    "            wordslist.append(word)\n",
    "            taglist.append(tags[i])\n",
    "    else:\n",
    "        wordParse = morph.parse(word)[0]\n",
    "        if \"PNCT\" not in wordParse.tag:\n",
    "            wordslist.append(word)\n",
    "            taglist.append(tags[i])\n",
    "words = wordslist.copy()\n",
    "tags = taglist.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordtovec(word, idd):\n",
    "    wordVector = [0 for i in range(27)]\n",
    "        \n",
    "    if word in [\"start_token\", \"end_token\", \"«\", \"»\"]:\n",
    "        if word == \"start_token\":\n",
    "            bracketCounter[word] += 1\n",
    "            if bracketCounter[word] == 2:\n",
    "                bracketCounter[word] = 1\n",
    "        if word in [\"«\", \"»\"]:\n",
    "            bracketCounter['bracket'] += 1\n",
    "            if bracketCounter['bracket'] == 3:\n",
    "                bracketCounter['bracket'] = 1\n",
    "        return wordVector\n",
    "        \n",
    "    tag = morph.parse(word)[0].tag\n",
    "    pos = morph.parse(word)[0].tag.POS\n",
    "    \n",
    "    if pos in [\"NOUN\", \"ADJF\", \"ADJS\", \"VERB\", \"PREP\", \"CONJ\"]: \n",
    "        if pos == 'NOUN':\n",
    "            wordVector[0] = 1\n",
    "        if pos == 'ADJF' or pos == 'ADJS':\n",
    "            wordVector[1] = 1\n",
    "        if pos == 'VERB':\n",
    "            wordVector[2] = 1\n",
    "        if pos == 'PREP':\n",
    "            wordVector[3] = 1\n",
    "        if pos == 'CONJ':\n",
    "            wordVector[4] = 1\n",
    "    else:\n",
    "        wordVector[5] = 1\n",
    "    if 'nomn' in tag:\n",
    "        wordVector[6] = 1\n",
    "    if 'gent' in tag:\n",
    "        wordVector[7] = 1\n",
    "    if 'datv' in tag:\n",
    "        wordVector[8] = 1\n",
    "    if 'accs' in tag:\n",
    "        wordVector[9] = 1\n",
    "    if 'ablt' in tag:\n",
    "        wordVector[10] = 1\n",
    "    if 'loct' in tag:\n",
    "        wordVector[11] = 1\n",
    "    if 'sing' in tag:\n",
    "        wordVector[12] = 1\n",
    "    if 'masc' in tag:\n",
    "        wordVector[13] = 1\n",
    "    if 'femn' in tag:\n",
    "        wordVector[14] = 1\n",
    "    if 'neut' in tag:\n",
    "        wordVector[15] = 1    \n",
    "    if len(word) > 1 and word[0].isupper() and word[1].islower():\n",
    "        wordVector[16] = 1    \n",
    "    if words[idd-1] == \"start_token\":\n",
    "        wordVector[17] = 1    \n",
    "    if words[idd+1] == \"end_token\":\n",
    "        wordVector[18] = 1        \n",
    "    if word.isupper():\n",
    "        wordVector[19] = 1\n",
    "    if word.islower():\n",
    "        wordVector[20] = 1\n",
    "    if bracketCounter[\"start_token\"] == 1 and bracketCounter[\"bracket\"] == 1:\n",
    "        wordVector[21] = 1\n",
    "    if 'anim' in tag:\n",
    "        wordVector[22] = 1\n",
    "    if \"-\" in word:\n",
    "        wordVector[23] = 1\n",
    "    if word.isdigit():\n",
    "        wordVector[24] = 1        \n",
    "    if tags[idd] == 'loc_descr':\n",
    "        wordVector[25] = 1\n",
    "        tags[idd] = 'not_ne'\n",
    "        \n",
    "    if tags[idd] == 'org_descr':\n",
    "        wordVector[26] = 1\n",
    "        tags[idd] = 'not_ne'\n",
    "        \n",
    "    return wordVector  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 84696/84696 [03:30<00:00, 402.48it/s]\n"
     ]
    }
   ],
   "source": [
    "bracketCounter = {\"start_token\":0, \"bracket\":0}\n",
    "\n",
    "wordvec = []\n",
    "for i, word in enumerate(tqdm(words)):\n",
    "    temp = []\n",
    "    temp = wordtovec(word, i)\n",
    "    wordvec.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 84696/84696 [00:01<00:00, 52139.75it/s]\n"
     ]
    }
   ],
   "source": [
    "len_of_win = 3\n",
    "vec_data = []\n",
    "for i, token in enumerate(tqdm(words)):\n",
    "    exvec = []\n",
    "    j = -1 * len_of_win\n",
    "    for _ in range(2*len_of_win+1):\n",
    "        try:\n",
    "            exvec.append(wordvec[i+j])\n",
    "        except Exception:\n",
    "            exvec.append([0 for i in range(27)])\n",
    "        j = j + 1\n",
    "    vec_data.append(exvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84696"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {'start':0, 'end':0}\n",
    "sentVector = []\n",
    "sentDictFeatures = []\n",
    "for i, token in enumerate(words):\n",
    "    if token == 'start_token':\n",
    "        state_dict['start'] += 1\n",
    "        if state_dict['start'] == 2:\n",
    "            state_dict['start'] = 1\n",
    "    if token == 'end_token':\n",
    "        state_dict['end'] += 1\n",
    "\n",
    "    if state_dict['start'] == 1 and state_dict['end'] == 0 and token != 'start_token':\n",
    "        wordVector = vectorData[i]\n",
    "        features = { str(k) : wordVector[k] for k in range(0, len(wordVector) ) }\n",
    "        sentVector.append(features)\n",
    "    if state_dict['end'] == 1:\n",
    "        state_dict['end'] = 0\n",
    "        sentDictFeatures.append(sentVector)\n",
    "        sentVector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4184"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = {'start':0, 'end':0}\n",
    "sentVector = []\n",
    "sentTagVectors = []\n",
    "for tag in tags:\n",
    "    if tag == 'start_state':\n",
    "        state_dict['start'] += 1\n",
    "        #print('предложение ' , i+1, ' началось')\n",
    "        if state_dict['start'] == 2:\n",
    "            state_dict['start'] = 1\n",
    "    if tag == 'end_state':\n",
    "        state_dict['end'] += 1\n",
    "\n",
    "    if state_dict['start'] == 1 and state_dict['end'] == 0 and tag != 'start_state':\n",
    "        sentVector.append(tag)\n",
    "    if state_dict['end'] == 1:\n",
    "        state_dict['end'] = 0\n",
    "        sentTagVectors.append(sentVector)\n",
    "        sentVector = []\n",
    "temp = []\n",
    "for i in sentTagVectors:\n",
    "    temp.append(i)\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 84696/84696 [00:13<00:00, 6242.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84696"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec_data = []\n",
    "for i in tqdm(vec_data):\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        for k in j:\n",
    "            temp.append(k)\n",
    "    new_vec_data.append(temp)\n",
    "len(new_vec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6965\n",
      "           1       0.89      0.78      0.84       372\n",
      "\n",
      "    accuracy                           0.98      7337\n",
      "   macro avg       0.94      0.89      0.91      7337\n",
      "weighted avg       0.98      0.98      0.98      7337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Conditional Random Fields (CRFs)\n",
    "X_crf = sentDictFeatures\n",
    "y_crf = sentTagVectors\n",
    "X_crf_train, X_crf_test, y_crf_train, y_crf_test = train_test_split(X_crf, y_crf, test_size=0.1)\n",
    "\n",
    "for i in y_crf_test:\n",
    "    for j, k in enumerate(i):\n",
    "        if k == 'not_ne':\n",
    "            i[j] = '0'\n",
    "        else:\n",
    "            i[j] = '1'\n",
    "            \n",
    "for i in y_crf_train:\n",
    "    for j, k in enumerate(i):\n",
    "        if k == 'not_ne':\n",
    "            i[j] = '0'\n",
    "        else:\n",
    "            i[j] = '1'\n",
    "\n",
    "            \n",
    "y = np.array(['0','1'])\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "new_classes = classes.copy()\n",
    "\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=new_classes)\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100\n",
    ")\n",
    "crf.fit(X_crf_train,\n",
    "        y_crf_train)\n",
    "\n",
    "y_crf_pred = crf.predict(X_crf_test)\n",
    "print(metrics.flat_classification_report(y_crf_test, y_crf_pred, labels = new_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-2db649b344b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_crf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_f1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_crf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_crf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_crf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mmodel_crf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_dev, y_dev)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_dev\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_log_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpycrfsuite\\_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpycrfsuite\\_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer._on_message\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpycrfsuite\\_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Trainer.message\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pycrfsuite\\_logparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# if line != '\\n':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'STARTING'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF()\n",
    "tuned_parameters = {\n",
    "    'c1': [(i+1)*0.05 for i in range(-5, 10)],\n",
    "    'c2': [(i+1)*0.05 for i in range(-5, 10)]\n",
    "}\n",
    "model_crf = GridSearchCV(crf, tuned_parameters, scoring = make_scorer(metrics.flat_f1_score, average='weighted'), cv=2)\n",
    "model_crf.fit(X_crf, y_crf)\n",
    "model_crf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8288043172560409"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "new_tags = tags.copy()\n",
    "for j, i in enumerate(new_tags):\n",
    "    if i == 'name' or i == 'surname':\n",
    "        new_tags[j] = 1\n",
    "    else:\n",
    "        new_tags[j] = 0\n",
    "\n",
    "X = np.array(new_expVectorData)\n",
    "y = np.array(new_tags)\n",
    "        \n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "new_classes = classes.copy()\n",
    "#new_classes.remove('end_state')\n",
    "#new_classes.remove('start_state')\n",
    "#new_classes.remove('start_state')\n",
    "print(new_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "sgd = SGDClassifier(**model.best_params_)\n",
    "sgd.fit(X_train, y_train)\n",
    "#print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))\n",
    "f1_score(sgd.predict(X_test), y_test)\n",
    "np.mean(cross_val_score(sgd, X, y, cv = 5, scoring = make_scorer(f1_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'max_iter': 750}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "tuned_parameters = {\n",
    "    'max_iter': [700 + i*50 for i in range(1, 10)],\n",
    "    'alpha': [0.0001,0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "model = GridSearchCV(sgd, tuned_parameters, scoring = make_scorer(f1_score), cv=2)\n",
    "model.fit(X_train, y_train)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7979583357251934"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "new_tags = tags.copy()\n",
    "for j, i in enumerate(new_tags):\n",
    "    if i == 'name' or i == 'surname':\n",
    "        new_tags[j] = 1\n",
    "    else:\n",
    "        new_tags[j] = 0\n",
    "\n",
    "X = np.array(new_expVectorData)\n",
    "y = np.array(new_tags)\n",
    "        \n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "new_classes = classes.copy()\n",
    "#new_classes.remove('end_state')\n",
    "#new_classes.remove('start_state')\n",
    "#new_classes.remove('start_state')\n",
    "print(new_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "#Linear classifiers with SGD training\n",
    "#sgd = SGDClassifier(max_iter=1000 , n_iter_no_change = 1000)\n",
    "#sgd.partial_fit(X_train, y_train, classes)\n",
    "#print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))\n",
    "\n",
    "tree = DecisionTreeClassifier(**model_tree.best_params_)\n",
    "tree.fit(X_train, y_train)\n",
    "#print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))\n",
    "f1_score(tree.predict(X_test), y_test)\n",
    "np.mean(cross_val_score(tree, X, y, cv = 5, scoring = make_scorer(f1_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\etrib\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 101, 'splitter': 'best'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tuned_parameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'], \n",
    "    'max_depth': [i for i in range(1, 181, 20)]\n",
    "}\n",
    "model_tree = GridSearchCV(tree, tuned_parameters, scoring = make_scorer(f1_score), cv=2)\n",
    "model_tree.fit(X_train, y_train)\n",
    "model_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(206, 0.4877091865383624),\n",
       " (212, 0.2007043711292018),\n",
       " (179, 0.02804225298354984),\n",
       " (207, 0.01962396456998924),\n",
       " (203, 0.012873112589778836),\n",
       " (185, 0.012442712854077824),\n",
       " (233, 0.009892567291415043),\n",
       " (202, 0.007943783683965326),\n",
       " (209, 0.007127942071165445),\n",
       " (175, 0.006891121877241599),\n",
       " (288, 0.005424452892842912),\n",
       " (197, 0.004898929838981856),\n",
       " (224, 0.004406592376917556),\n",
       " (230, 0.0027462993839440734),\n",
       " (167, 0.0023934575752093943),\n",
       " (158, 0.002382488260176882),\n",
       " (260, 0.002364116305937557),\n",
       " (178, 0.0022616574077429508),\n",
       " (33, 0.0022567692517141244),\n",
       " (219, 0.002234804540593583),\n",
       " (237, 0.002170474413010081),\n",
       " (163, 0.002158828288960738),\n",
       " (131, 0.0021183272711280537),\n",
       " (104, 0.0018782624090303928),\n",
       " (278, 0.0018603564461082687),\n",
       " (239, 0.0017662276049801489),\n",
       " (148, 0.0017628813292589122),\n",
       " (284, 0.0017193600357596254),\n",
       " (213, 0.0016703341572058502),\n",
       " (217, 0.001629107801114352),\n",
       " (201, 0.0016289171243829075),\n",
       " (190, 0.001617082322073469),\n",
       " (128, 0.0016147430289218418),\n",
       " (337, 0.0016059883475440556),\n",
       " (71, 0.0015986448807518957),\n",
       " (48, 0.0015906010057138334),\n",
       " (200, 0.0015379479332503553),\n",
       " (222, 0.0015040748642900933),\n",
       " (169, 0.001482437007145162),\n",
       " (369, 0.001472896808860544),\n",
       " (229, 0.0014653787396117736),\n",
       " (325, 0.0014495457714584587),\n",
       " (115, 0.0014108949964427959),\n",
       " (22, 0.0014058612582622772),\n",
       " (264, 0.0013898931349281302),\n",
       " (247, 0.0013885540622686574),\n",
       " (244, 0.0013850760037346036),\n",
       " (195, 0.0013616329224426331),\n",
       " (301, 0.0013416491503818685),\n",
       " (391, 0.0013414015011525384),\n",
       " (223, 0.0013333524820487632),\n",
       " (52, 0.0012785746210274061),\n",
       " (68, 0.0012712664447428236),\n",
       " (49, 0.0012549086789635346),\n",
       " (40, 0.0012361600828419371),\n",
       " (125, 0.00121462781387387),\n",
       " (165, 0.0012088994861016165),\n",
       " (77, 0.0011973994458232542),\n",
       " (210, 0.0011917126414550047),\n",
       " (298, 0.0011502250090766808),\n",
       " (204, 0.0011076548596856864),\n",
       " (14, 0.0011047866757968228),\n",
       " (186, 0.001089285231311908),\n",
       " (170, 0.0010890499799461122),\n",
       " (156, 0.001072229108564765),\n",
       " (73, 0.0010611355150615934),\n",
       " (236, 0.0010535031340452806),\n",
       " (345, 0.0010485076674832323),\n",
       " (318, 0.0010477153647569684),\n",
       " (137, 0.0010425924796287416),\n",
       " (187, 0.001040866014377364),\n",
       " (136, 0.0010368851071935854),\n",
       " (118, 0.001031791709528897),\n",
       " (238, 0.0010301024617088358),\n",
       " (97, 0.0010119889069726122),\n",
       " (143, 0.001010326690822906),\n",
       " (312, 0.0010068667306017602),\n",
       " (286, 0.000988357909248872),\n",
       " (98, 0.000984646972056042),\n",
       " (250, 0.000983417406267589),\n",
       " (121, 0.000971102992949527),\n",
       " (364, 0.0009610962746345961),\n",
       " (88, 0.0009572204324903958),\n",
       " (359, 0.0009539404260514399),\n",
       " (109, 0.0009315137610207367),\n",
       " (91, 0.0009257807870324905),\n",
       " (29, 0.0009223737712288254),\n",
       " (76, 0.0009126095155846421),\n",
       " (392, 0.000909102181682127),\n",
       " (62, 0.0009072972962433727),\n",
       " (168, 0.000905709980334765),\n",
       " (366, 0.0008904089050361381),\n",
       " (28, 0.0008838715740378514),\n",
       " (283, 0.0008746263242381093),\n",
       " (332, 0.0008668643780132979),\n",
       " (248, 0.0008568708708555343),\n",
       " (84, 0.0008551178749646984),\n",
       " (2, 0.0008136380319744943),\n",
       " (292, 0.0008127245896365748),\n",
       " (114, 0.0008062029728637999),\n",
       " (142, 0.0007956157575858794),\n",
       " (172, 0.0007532556451223646),\n",
       " (61, 0.0007522536287885738),\n",
       " (130, 0.0007479954343247332),\n",
       " (390, 0.0007395049325583144),\n",
       " (7, 0.000730961252057999),\n",
       " (127, 0.0007280731932198619),\n",
       " (176, 0.0007274597549264522),\n",
       " (291, 0.000722730015758134),\n",
       " (164, 0.000721477011477588),\n",
       " (353, 0.0007176261616574563),\n",
       " (246, 0.0007126868030666768),\n",
       " (346, 0.0007017681049909923),\n",
       " (356, 0.0006985238615400449),\n",
       " (221, 0.000696464523545895),\n",
       " (273, 0.0006945804050976709),\n",
       " (116, 0.0006907152082001654),\n",
       " (277, 0.0006905091147516837),\n",
       " (293, 0.0006902733467194877),\n",
       " (132, 0.0006881840521493863),\n",
       " (12, 0.000682522067472965),\n",
       " (382, 0.0006733180129676257),\n",
       " (42, 0.0006674656749194469),\n",
       " (17, 0.0006571231550104256),\n",
       " (124, 0.0006557339972293308),\n",
       " (303, 0.0006523194906405061),\n",
       " (50, 0.0006506707356477837),\n",
       " (372, 0.0006415142079864455),\n",
       " (171, 0.0006395367296124992),\n",
       " (231, 0.0006373270939763888),\n",
       " (180, 0.0006311599368204344),\n",
       " (70, 0.0006302619086340822),\n",
       " (257, 0.0006263518477589619),\n",
       " (149, 0.0006212135247164423),\n",
       " (82, 0.0006183326332898893),\n",
       " (327, 0.0006166289662882316),\n",
       " (240, 0.0006094185697037636),\n",
       " (103, 0.0006021337012063496),\n",
       " (287, 0.0006018442192587247),\n",
       " (393, 0.0006016111434721578),\n",
       " (348, 0.0005897487282150967),\n",
       " (256, 0.0005880334504142902),\n",
       " (354, 0.0005869061872237032),\n",
       " (258, 0.000580432941439893),\n",
       " (267, 0.0005679029753310562),\n",
       " (255, 0.0005623873782363057),\n",
       " (401, 0.0005613684006809038),\n",
       " (374, 0.0005607396731340859),\n",
       " (41, 0.0005586264267486278),\n",
       " (274, 0.0005527085778323983),\n",
       " (309, 0.0005472138763173695),\n",
       " (65, 0.0005459201970566679),\n",
       " (86, 0.0005455735766660274),\n",
       " (397, 0.0005445250037511021),\n",
       " (232, 0.0005422476444354815),\n",
       " (280, 0.0005366918663536286),\n",
       " (196, 0.0005252209192658737),\n",
       " (368, 0.0005219731071688791),\n",
       " (111, 0.0005185366232843568),\n",
       " (56, 0.0005182689190536733),\n",
       " (72, 0.0005146894041620666),\n",
       " (35, 0.0005054850343244812),\n",
       " (63, 0.00050280660175272),\n",
       " (367, 0.0004982647158688781),\n",
       " (140, 0.0004934009136629203),\n",
       " (177, 0.0004910733853652542),\n",
       " (384, 0.0004890711521919796),\n",
       " (241, 0.00048406148297336105),\n",
       " (123, 0.00047891337243634216),\n",
       " (122, 0.00047718916999013497),\n",
       " (251, 0.00047443917481956415),\n",
       " (139, 0.00047266868780695325),\n",
       " (13, 0.0004705354503206471),\n",
       " (55, 0.00046794369344487657),\n",
       " (226, 0.0004667647931320559),\n",
       " (44, 0.0004634514426772875),\n",
       " (39, 0.0004553659276501135),\n",
       " (37, 0.00045247989047120723),\n",
       " (5, 0.00045203181026678556),\n",
       " (365, 0.00044570895402870565),\n",
       " (31, 0.00044099554750530055),\n",
       " (184, 0.00043997434892484587),\n",
       " (141, 0.00043574364325429184),\n",
       " (268, 0.00042356364530451616),\n",
       " (198, 0.0004071362638485864),\n",
       " (299, 0.0004032881120163714),\n",
       " (276, 0.0004027884368362),\n",
       " (220, 0.0003960507316497917),\n",
       " (101, 0.0003934172600431641),\n",
       " (87, 0.00038874565403989675),\n",
       " (16, 0.00038682859862780795),\n",
       " (94, 0.00038526213121551744),\n",
       " (47, 0.0003808547147963614),\n",
       " (308, 0.0003801549181271299),\n",
       " (75, 0.00037734586684225413),\n",
       " (389, 0.00037480710651487185),\n",
       " (96, 0.00037009136907246033),\n",
       " (21, 0.00036894060212101266),\n",
       " (83, 0.00036452782362801227),\n",
       " (338, 0.0003625611198127471),\n",
       " (152, 0.0003589246491689662),\n",
       " (333, 0.00035767135651097325),\n",
       " (263, 0.0003570625719168795),\n",
       " (396, 0.0003560331654625349),\n",
       " (191, 0.0003526509477219994),\n",
       " (113, 0.0003521264025949701),\n",
       " (34, 0.00034116789657041814),\n",
       " (339, 0.00034101745527994096),\n",
       " (173, 0.00033841218179260426),\n",
       " (386, 0.0003380789555169314),\n",
       " (32, 0.0003375133713501347),\n",
       " (24, 0.0003346433839989675),\n",
       " (358, 0.00033244857052828),\n",
       " (352, 0.00033235224131575476),\n",
       " (376, 0.00032400913614568245),\n",
       " (129, 0.0003201592617681651),\n",
       " (344, 0.0003200875462277876),\n",
       " (182, 0.0003193788509619328),\n",
       " (322, 0.0003157863691572754),\n",
       " (95, 0.00031336934135791126),\n",
       " (110, 0.0003125635638691695),\n",
       " (340, 0.0003122445079149405),\n",
       " (329, 0.0003112544515495737),\n",
       " (99, 0.00030961391824021556),\n",
       " (15, 0.0003088110976672387),\n",
       " (285, 0.00030779059228560615),\n",
       " (275, 0.0003065240001211886),\n",
       " (147, 0.0003065109633170824),\n",
       " (120, 0.00030401104654995543),\n",
       " (10, 0.0003014706315073105),\n",
       " (60, 0.0002983011030117761),\n",
       " (380, 0.0002951506707290147),\n",
       " (58, 0.00029033226337496043),\n",
       " (205, 0.0002898635303304112),\n",
       " (279, 0.00028545715247861754),\n",
       " (383, 0.00028468655973722644),\n",
       " (79, 0.00028184834711148877),\n",
       " (272, 0.0002818483471114887),\n",
       " (347, 0.0002807462845189384),\n",
       " (18, 0.0002801083520317595),\n",
       " (119, 0.00027942803282631233),\n",
       " (313, 0.0002776015331616958),\n",
       " (300, 0.0002774028340961888),\n",
       " (331, 0.00027284582110113123),\n",
       " (150, 0.0002711993305648337),\n",
       " (112, 0.00027017264309118783),\n",
       " (235, 0.0002630818211651464),\n",
       " (265, 0.00025640908041353095),\n",
       " (245, 0.00025371053415860936),\n",
       " (319, 0.0002533958656028571),\n",
       " (305, 0.0002518696099824967),\n",
       " (8, 0.0002514044347891986),\n",
       " (146, 0.0002493326607796414),\n",
       " (394, 0.00024291957008975836),\n",
       " (249, 0.00024274305524013844),\n",
       " (336, 0.00023136683507271431),\n",
       " (271, 0.0002303190533556949),\n",
       " (361, 0.0002261702153030817),\n",
       " (314, 0.00022505697890983368),\n",
       " (294, 0.00022468398314113156),\n",
       " (59, 0.00021661225557956682),\n",
       " (23, 0.00021251303871826983),\n",
       " (307, 0.00020887630750884376),\n",
       " (102, 0.00020866582366994396),\n",
       " (160, 0.00020400884764453056),\n",
       " (74, 0.00018128055990637354),\n",
       " (85, 0.00018128055990637354),\n",
       " (388, 0.00018128055990637354),\n",
       " (395, 0.00016683649707852644),\n",
       " (9, 0.00015389529614280307),\n",
       " (183, 0.00015389529614280307),\n",
       " (253, 0.00015389529614280307),\n",
       " (403, 0.00015389529614280307),\n",
       " (89, 0.00011172528534972554),\n",
       " (362, 0.00011172528534972554),\n",
       " (1, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (6, 0.0),\n",
       " (11, 0.0),\n",
       " (19, 0.0),\n",
       " (20, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (30, 0.0),\n",
       " (36, 0.0),\n",
       " (38, 0.0),\n",
       " (43, 0.0),\n",
       " (45, 0.0),\n",
       " (46, 0.0),\n",
       " (51, 0.0),\n",
       " (53, 0.0),\n",
       " (54, 0.0),\n",
       " (57, 0.0),\n",
       " (64, 0.0),\n",
       " (66, 0.0),\n",
       " (67, 0.0),\n",
       " (69, 0.0),\n",
       " (78, 0.0),\n",
       " (80, 0.0),\n",
       " (81, 0.0),\n",
       " (90, 0.0),\n",
       " (92, 0.0),\n",
       " (93, 0.0),\n",
       " (100, 0.0),\n",
       " (105, 0.0),\n",
       " (106, 0.0),\n",
       " (107, 0.0),\n",
       " (108, 0.0),\n",
       " (117, 0.0),\n",
       " (126, 0.0),\n",
       " (133, 0.0),\n",
       " (134, 0.0),\n",
       " (135, 0.0),\n",
       " (138, 0.0),\n",
       " (144, 0.0),\n",
       " (145, 0.0),\n",
       " (151, 0.0),\n",
       " (153, 0.0),\n",
       " (154, 0.0),\n",
       " (155, 0.0),\n",
       " (157, 0.0),\n",
       " (159, 0.0),\n",
       " (161, 0.0),\n",
       " (162, 0.0),\n",
       " (166, 0.0),\n",
       " (174, 0.0),\n",
       " (181, 0.0),\n",
       " (188, 0.0),\n",
       " (189, 0.0),\n",
       " (192, 0.0),\n",
       " (193, 0.0),\n",
       " (194, 0.0),\n",
       " (199, 0.0),\n",
       " (208, 0.0),\n",
       " (211, 0.0),\n",
       " (214, 0.0),\n",
       " (215, 0.0),\n",
       " (216, 0.0),\n",
       " (218, 0.0),\n",
       " (225, 0.0),\n",
       " (227, 0.0),\n",
       " (228, 0.0),\n",
       " (234, 0.0),\n",
       " (242, 0.0),\n",
       " (243, 0.0),\n",
       " (252, 0.0),\n",
       " (254, 0.0),\n",
       " (259, 0.0),\n",
       " (261, 0.0),\n",
       " (262, 0.0),\n",
       " (266, 0.0),\n",
       " (269, 0.0),\n",
       " (270, 0.0),\n",
       " (281, 0.0),\n",
       " (282, 0.0),\n",
       " (289, 0.0),\n",
       " (290, 0.0),\n",
       " (295, 0.0),\n",
       " (296, 0.0),\n",
       " (297, 0.0),\n",
       " (302, 0.0),\n",
       " (304, 0.0),\n",
       " (306, 0.0),\n",
       " (310, 0.0),\n",
       " (311, 0.0),\n",
       " (315, 0.0),\n",
       " (316, 0.0),\n",
       " (317, 0.0),\n",
       " (320, 0.0),\n",
       " (321, 0.0),\n",
       " (323, 0.0),\n",
       " (324, 0.0),\n",
       " (326, 0.0),\n",
       " (328, 0.0),\n",
       " (330, 0.0),\n",
       " (334, 0.0),\n",
       " (335, 0.0),\n",
       " (341, 0.0),\n",
       " (342, 0.0),\n",
       " (343, 0.0),\n",
       " (349, 0.0),\n",
       " (350, 0.0),\n",
       " (351, 0.0),\n",
       " (355, 0.0),\n",
       " (357, 0.0),\n",
       " (360, 0.0),\n",
       " (363, 0.0),\n",
       " (370, 0.0),\n",
       " (371, 0.0),\n",
       " (373, 0.0),\n",
       " (375, 0.0),\n",
       " (377, 0.0),\n",
       " (378, 0.0),\n",
       " (379, 0.0),\n",
       " (381, 0.0),\n",
       " (385, 0.0),\n",
       " (387, 0.0),\n",
       " (398, 0.0),\n",
       " (399, 0.0),\n",
       " (400, 0.0),\n",
       " (402, 0.0),\n",
       " (404, 0.0),\n",
       " (405, 0.0)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tree.feature_importances_))\n",
    "temp = list(zip(range(1, 406), tree.feature_importances_))\n",
    "temp.sort(key = lambda x: x[1], reverse = True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(206, 0.0685005393743245),\n",
       " (212, 0.06564185544767957),\n",
       " (210, -0.0327939590075516),\n",
       " (179, 0.023894282632146772),\n",
       " (233, 0.021089536138079793),\n",
       " (202, 0.019848975188781082),\n",
       " (185, 0.016936353829557705),\n",
       " (165, 0.015695792880258897),\n",
       " (195, 0.014239482200647259),\n",
       " (239, 0.014239482200647236),\n",
       " (167, 0.013754045307443383),\n",
       " (190, 0.01272923408845745),\n",
       " (221, 0.01272923408845742),\n",
       " (191, 0.012675296655879216),\n",
       " (208, 0.011920172599784297),\n",
       " (288, 0.011812297734627877),\n",
       " (168, 0.011812297734627865),\n",
       " (235, 0.011812297734627863),\n",
       " (213, -0.011218985976267574),\n",
       " (209, 0.011218985976267573),\n",
       " (217, -0.011165048543689394),\n",
       " (72, 0.010841423948220111),\n",
       " (128, 0.010625674217907258),\n",
       " (203, 0.01040992448759447),\n",
       " (198, 0.010409924487594426),\n",
       " (343, 0.010302049622437987),\n",
       " (219, 0.010140237324703386),\n",
       " (160, 0.010140237324703379),\n",
       " (131, 0.009762675296655893),\n",
       " (201, -0.009223300970873805),\n",
       " (163, 0.009169363538295604),\n",
       " (315, 0.0091154261057174),\n",
       " (224, -0.009061488673139183),\n",
       " (175, 0.00889967637540456),\n",
       " (200, 0.008791801510248153),\n",
       " (220, 0.008629989212513532),\n",
       " (104, 0.008468176914778868),\n",
       " (182, 0.00825242718446606),\n",
       " (99, 0.008036677454153214),\n",
       " (155, 0.007982740021574997),\n",
       " (126, 0.007766990291262181),\n",
       " (138, 0.007659115426105742),\n",
       " (396, 0.007605177993527552),\n",
       " (230, 0.00760517799352752),\n",
       " (369, 0.007551240560949317),\n",
       " (141, 0.007497303128371083),\n",
       " (276, 0.007443365695792898),\n",
       " (222, 0.007389428263214693),\n",
       " (349, 0.00711974110032365),\n",
       " (342, 0.007119741100323648),\n",
       " (289, 0.007119741100323638),\n",
       " (153, 0.007065803667745449),\n",
       " (211, 0.006850053937432609),\n",
       " (19, 0.0066343042071197586),\n",
       " (290, 0.006580366774541569),\n",
       " (77, 0.0065264293419633555),\n",
       " (186, -0.006472491909385145),\n",
       " (262, 0.006472491909385129),\n",
       " (229, 0.00636461704422868),\n",
       " (316, 0.006256742179072307),\n",
       " (204, -0.006202804746494101),\n",
       " (47, 0.006202804746494093),\n",
       " (344, 0.006202804746494087),\n",
       " (265, -0.006202804746494059),\n",
       " (264, 0.00609492988133768),\n",
       " (232, -0.006094929881337676),\n",
       " (295, 0.006094929881337666),\n",
       " (187, 0.0060409924487594665),\n",
       " (143, 0.005987055016181214),\n",
       " (25, 0.005933117583603048),\n",
       " (251, -0.005879180151024838),\n",
       " (370, 0.005825242718446635),\n",
       " (260, -0.005663430420711984),\n",
       " (322, 0.005609492988133792),\n",
       " (164, -0.005555555555555576),\n",
       " (23, 0.0054476806903991605),\n",
       " (140, 0.00539374325782094),\n",
       " (114, 0.0052858683926644955),\n",
       " (248, 0.005231930960086319),\n",
       " (275, 0.005231930960086319),\n",
       " (283, 0.00523193096008631),\n",
       " (237, 0.005177993527508121),\n",
       " (86, 0.00517799352750811),\n",
       " (300, 0.005124056094929915),\n",
       " (132, 0.0050701186623517),\n",
       " (136, 0.0050701186623517),\n",
       " (246, 0.005016181229773468),\n",
       " (178, 0.0050161812297734665),\n",
       " (327, 0.004962243797195258),\n",
       " (29, 0.004908306364617066),\n",
       " (65, -0.004854368932038846),\n",
       " (111, 0.004746494066882443),\n",
       " (381, 0.004746494066882421),\n",
       " (5, 0.004692556634304229),\n",
       " (112, 0.004638619201726019),\n",
       " (121, 0.004638619201726007),\n",
       " (71, 0.004638619201725986),\n",
       " (308, 0.004584681769147805),\n",
       " (258, 0.004530744336569613),\n",
       " (183, 0.004530744336569594),\n",
       " (133, 0.004530744336569591),\n",
       " (60, 0.004422869471413182),\n",
       " (268, 0.0044228694714131735),\n",
       " (357, 0.0044228694714131735),\n",
       " (21, 0.0044228694714131276),\n",
       " (398, 0.004314994606256769),\n",
       " (263, 0.004314994606256756),\n",
       " (247, 0.004314994606256735),\n",
       " (66, 0.0042610571736785615),\n",
       " (318, 0.0042610571736785485),\n",
       " (374, 0.004261057173678542),\n",
       " (192, 0.004207119741100347),\n",
       " (274, 0.00415318230852214),\n",
       " (46, 0.004099244875943917),\n",
       " (98, 0.004045307443365705),\n",
       " (177, 0.004045307443365693),\n",
       " (228, -0.003991370010787511),\n",
       " (184, 0.0039913700107875065),\n",
       " (244, -0.003991370010787503),\n",
       " (335, 0.003937432578209282),\n",
       " (249, 0.003883495145631077),\n",
       " (75, 0.0038834951456310552),\n",
       " (17, 0.0038295577130529074),\n",
       " (144, -0.0037756202804746595),\n",
       " (4, 0.00377562028047465),\n",
       " (371, 0.003775620280474647),\n",
       " (284, 0.003775620280474644),\n",
       " (395, 0.003721682847896445),\n",
       " (193, 0.0036677454153182486),\n",
       " (355, 0.003667745415318244),\n",
       " (326, 0.003613807982740034),\n",
       " (205, -0.00355987055016183),\n",
       " (171, 0.003559870550161823),\n",
       " (303, 0.0035598705501618064),\n",
       " (330, 0.0035598705501617947),\n",
       " (57, 0.0035059331175836144),\n",
       " (110, 0.003505933117583606),\n",
       " (317, 0.0034519956850054033),\n",
       " (346, 0.0034519956850054033),\n",
       " (199, -0.0033980582524272187),\n",
       " (102, 0.003398058252427194),\n",
       " (272, 0.0033980582524271875),\n",
       " (152, 0.0033980582524271844),\n",
       " (62, 0.003398058252427165),\n",
       " (6, 0.0033441208198489894),\n",
       " (44, 0.003344120819848977),\n",
       " (401, 0.003344120819848971),\n",
       " (33, 0.0033441208198489642),\n",
       " (345, 0.0032901833872707965),\n",
       " (158, 0.003290183387270785),\n",
       " (196, 0.0032362459546925806),\n",
       " (180, 0.003236245954692577),\n",
       " (314, 0.0031823085221143687),\n",
       " (257, 0.0031823085221143457),\n",
       " (83, 0.0031283710895361563),\n",
       " (238, -0.003128371089536147),\n",
       " (328, 0.003074433656957962),\n",
       " (287, 0.003074433656957938),\n",
       " (373, 0.003074433656957931),\n",
       " (13, 0.003020496224379754),\n",
       " (174, -0.003020496224379732),\n",
       " (59, 0.0030204962243797293),\n",
       " (32, 0.002966558791801521),\n",
       " (79, 0.0029665587918015195),\n",
       " (113, 0.0029126213592233136),\n",
       " (14, -0.0029126213592233032),\n",
       " (31, 0.002858683926645118),\n",
       " (368, 0.0028586839266450913),\n",
       " (226, -0.002804746494066903),\n",
       " (159, 0.0028047464940668754),\n",
       " (129, 0.002750809061488705),\n",
       " (34, 0.002750809061488696),\n",
       " (334, 0.0026429341963322807),\n",
       " (123, -0.0026429341963322777),\n",
       " (253, 0.0026429341963322673),\n",
       " (45, 0.0026429341963322664),\n",
       " (10, 0.0026429341963322634),\n",
       " (103, -0.0026429341963322447),\n",
       " (384, 0.002588996763754066),\n",
       " (124, 0.002588996763754058),\n",
       " (360, -0.002535059331175853),\n",
       " (105, 0.0024811218985976518),\n",
       " (399, 0.002481121898597651),\n",
       " (329, 0.0024811218985976453),\n",
       " (338, 0.00248112189859764),\n",
       " (70, 0.002427184466019442),\n",
       " (87, 0.002427184466019442),\n",
       " (286, 0.002427184466019431),\n",
       " (48, 0.0023732470334412183),\n",
       " (356, 0.0023732470334412157),\n",
       " (236, -0.0023732470334412127),\n",
       " (56, 0.0023732470334411966),\n",
       " (385, -0.002319309600863015),\n",
       " (347, 0.002319309600862998),\n",
       " (197, 0.002319309600862993),\n",
       " (148, 0.0023193096008629847),\n",
       " (227, -0.002265372168284806),\n",
       " (55, -0.0022653721682847883),\n",
       " (250, -0.0022653721682847675),\n",
       " (1, 0.002211434735706597),\n",
       " (30, 0.002211434735706586),\n",
       " (291, 0.0022114347357065833),\n",
       " (299, 0.002157497303128408),\n",
       " (364, 0.002157497303128396),\n",
       " (122, -0.0021574973031283848),\n",
       " (51, 0.002157497303128384),\n",
       " (157, -0.0021574973031283726),\n",
       " (298, 0.00215749730312837),\n",
       " (139, 0.002103559870550191),\n",
       " (49, 0.002103559870550182),\n",
       " (8, 0.0021035598705501785),\n",
       " (92, -0.0021035598705501767),\n",
       " (101, 0.0020496224379719695),\n",
       " (358, -0.0020496224379719487),\n",
       " (302, 0.001995685005393759),\n",
       " (379, 0.0019956850053937584),\n",
       " (147, -0.001995685005393753),\n",
       " (337, 0.0019956850053937433),\n",
       " (2, 0.0019417475728155521),\n",
       " (231, -0.0019417475728155424),\n",
       " (363, 0.0018878101402373397),\n",
       " (120, -0.00188781014023733),\n",
       " (127, -0.0018878101402373265),\n",
       " (348, 0.0018878101402373174),\n",
       " (117, 0.0018338727076591262),\n",
       " (119, 0.0018338727076591206),\n",
       " (169, 0.0018338727076591178),\n",
       " (50, 0.0018338727076590926),\n",
       " (354, 0.0017799352750809442),\n",
       " (285, -0.0017799352750809043),\n",
       " (73, 0.0017799352750809008),\n",
       " (125, 0.0017799352750809),\n",
       " (15, 0.0017259978425027186),\n",
       " (367, 0.0017259978425026975),\n",
       " (68, 0.001725997842502682),\n",
       " (156, 0.0016720604099244904),\n",
       " (176, 0.0016720604099244886),\n",
       " (84, 0.0016720604099244836),\n",
       " (375, 0.0016181229773462795),\n",
       " (106, 0.0016181229773462793),\n",
       " (67, 0.0015641855447680762),\n",
       " (35, 0.0015641855447680755),\n",
       " (223, 0.001564185544768039),\n",
       " (332, 0.0015102481121899054),\n",
       " (325, 0.0015102481121898766),\n",
       " (390, 0.0015102481121898694),\n",
       " (94, -0.0015102481121898577),\n",
       " (11, 0.0014563106796116674),\n",
       " (273, -0.0014563106796116631),\n",
       " (256, 0.0013484358144552617),\n",
       " (307, -0.0013484358144552474),\n",
       " (293, 0.001348435814455245),\n",
       " (393, 0.001348435814455242),\n",
       " (304, -0.0013484358144552407),\n",
       " (38, 0.001348435814455235),\n",
       " (76, -0.0013484358144552238),\n",
       " (380, 0.0013484358144552234),\n",
       " (397, -0.0012944983818770376),\n",
       " (321, -0.0012944983818770357),\n",
       " (389, 0.001294498381877029),\n",
       " (339, 0.0012944983818770242),\n",
       " (301, 0.0012944983818770146),\n",
       " (331, -0.001240560949298859),\n",
       " (372, 0.0012405609492988465),\n",
       " (41, 0.0012405609492988263),\n",
       " (42, -0.0012405609492988161),\n",
       " (305, 0.0012405609492988066),\n",
       " (61, 0.0012405609492988005),\n",
       " (12, 0.001186623516720625),\n",
       " (311, 0.001186623516720598),\n",
       " (194, 0.0011326860841424063),\n",
       " (218, 0.001132686084142403),\n",
       " (24, 0.001132686084142401),\n",
       " (43, 0.0011326860841423987),\n",
       " (280, 0.0011326860841423944),\n",
       " (52, 0.0011326860841423924),\n",
       " (333, 0.0011326860841423861),\n",
       " (359, 0.0011326860841423803),\n",
       " (266, -0.0010787486515642264),\n",
       " (95, -0.0010787486515642173),\n",
       " (340, 0.0010787486515641967),\n",
       " (252, -0.0010248112189859817),\n",
       " (392, 0.0010248112189859815),\n",
       " (306, -0.0010248112189859668),\n",
       " (207, -0.0010248112189859661),\n",
       " (173, -0.0009708737864077871),\n",
       " (292, 0.0009708737864077797),\n",
       " (16, 0.0009708737864077691),\n",
       " (281, -0.0009169363538295681),\n",
       " (271, 0.0009169363538295638),\n",
       " (387, -0.0009169363538295615),\n",
       " (91, 0.0009169363538295564),\n",
       " (382, 0.0008629989212513638),\n",
       " (145, -0.0008629989212513502),\n",
       " (28, -0.0008629989212513499),\n",
       " (388, -0.0008629989212513475),\n",
       " (366, 0.000862998921251334),\n",
       " (137, -0.0008090614886731573),\n",
       " (142, 0.0008090614886731461),\n",
       " (254, 0.0008090614886731432),\n",
       " (90, -0.0008090614886731431),\n",
       " (394, 0.0008090614886731423),\n",
       " (149, -0.0008090614886731382),\n",
       " (277, -0.0008090614886731278),\n",
       " (82, -0.0007551240560949502),\n",
       " (313, -0.0007551240560949327),\n",
       " (361, 0.000701186623516733),\n",
       " (376, 0.0007011866235167282),\n",
       " (353, -0.0007011866235167234),\n",
       " (7, 0.0007011866235167206),\n",
       " (63, -0.0007011866235167146),\n",
       " (40, 0.0006472491909385331),\n",
       " (391, 0.0006472491909385294),\n",
       " (118, -0.0006472491909385156),\n",
       " (279, -0.0006472491909385147),\n",
       " (282, -0.0006472491909385126),\n",
       " (255, -0.0006472491909385087),\n",
       " (109, -0.0006472491909385073),\n",
       " (88, 0.0005933117583603033),\n",
       " (170, -0.000593311758360295),\n",
       " (312, 0.0005393743257821157),\n",
       " (97, 0.0005393743257820989),\n",
       " (267, 0.0005393743257820854),\n",
       " (319, -0.0005393743257820837),\n",
       " (166, 0.00048543689320391833),\n",
       " (115, -0.0004854368932039042),\n",
       " (93, -0.00048543689320389925),\n",
       " (96, -0.0004854368932038857),\n",
       " (39, -0.00048543689320388434),\n",
       " (20, 0.0004854368932038786),\n",
       " (22, -0.00048543689320386884),\n",
       " (245, 0.00043149946062569715),\n",
       " (241, -0.00043149946062567753),\n",
       " (309, -0.000431499460625661),\n",
       " (58, 0.0004314994606256549),\n",
       " (151, -0.0003775620280474905),\n",
       " (362, -0.0003775620280474808),\n",
       " (37, -0.0003775620280474805),\n",
       " (69, -0.00032362459546926694),\n",
       " (85, 0.0003236245954692571),\n",
       " (64, -0.0003236245954692569),\n",
       " (402, -0.0003236245954692541),\n",
       " (36, -0.0003236245954692526),\n",
       " (386, 0.0003236245954692511),\n",
       " (172, -0.00026968716289105883),\n",
       " (9, -0.00026968716289104745),\n",
       " (74, 0.0002157497303128474),\n",
       " (403, -0.00021574973031284017),\n",
       " (150, 0.00021574973031283343),\n",
       " (116, -0.00021574973031283077),\n",
       " (146, 0.00021574973031283034),\n",
       " (310, -0.0002157497303128296),\n",
       " (352, -0.0001618122977346409),\n",
       " (278, -0.0001618122977346376),\n",
       " (130, -0.00016181229773461303),\n",
       " (259, -0.0001618122977346124),\n",
       " (383, 0.00010787486515642203),\n",
       " (78, -0.00010787486515642171),\n",
       " (400, -0.00010787486515641724),\n",
       " (181, -0.00010787486515641646),\n",
       " (261, -0.00010787486515641646),\n",
       " (100, -0.00010787486515641109),\n",
       " (89, -0.00010787486515639323),\n",
       " (341, 0.00010787486515639049),\n",
       " (365, -0.00010787486515638917),\n",
       " (18, 5.3937432578217335e-05),\n",
       " (240, 5.393743257821367e-05),\n",
       " (214, -5.3937432578208214e-05),\n",
       " (294, 5.393743257820403e-05),\n",
       " (320, -1.5019314541909325e-17),\n",
       " (3, -9.894280532966775e-18),\n",
       " (225, -4.5574682591918885e-18),\n",
       " (336, 3.871306681135117e-18),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (53, 0.0),\n",
       " (54, 0.0),\n",
       " (80, 0.0),\n",
       " (81, 0.0),\n",
       " (107, 0.0),\n",
       " (108, 0.0),\n",
       " (134, 0.0),\n",
       " (135, 0.0),\n",
       " (154, 0.0),\n",
       " (161, 0.0),\n",
       " (162, 0.0),\n",
       " (188, 0.0),\n",
       " (189, 0.0),\n",
       " (215, 0.0),\n",
       " (216, 0.0),\n",
       " (234, 0.0),\n",
       " (242, 0.0),\n",
       " (243, 0.0),\n",
       " (269, 0.0),\n",
       " (270, 0.0),\n",
       " (296, 0.0),\n",
       " (297, 0.0),\n",
       " (323, 0.0),\n",
       " (324, 0.0),\n",
       " (350, 0.0),\n",
       " (351, 0.0),\n",
       " (377, 0.0),\n",
       " (378, 0.0),\n",
       " (404, 0.0),\n",
       " (405, 0.0)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = []\n",
    "for i in sgd.coef_:\n",
    "    for j in i:\n",
    "        weights.append(j)\n",
    "weights = np.array(weights)\n",
    "weights = weights/np.sum(weights)\n",
    "weights\n",
    "temp = list(zip(range(1, 406), weights))\n",
    "temp.sort(key = lambda x: abs(x[1]), reverse = True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
