{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdtri\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "C:\\Users\\vdtri\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:172: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from umap import UMAP\n",
    "from math import log\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('ru')\n",
    "from pymystem3 import Mystem\n",
    "from collections import defaultdict\n",
    "import artm\n",
    "import math\n",
    "import top2vec\n",
    "from top2vec import Top2Vec\n",
    "from scipy.spatial import distance\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import gensim\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import median, variance\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"[а-яА-ЯёЁ]+\")\n",
    "m = Mystem()\n",
    "model_path = r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\\\'\n",
    "path_to_prog = r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\\\'\n",
    "\n",
    "def stemming(text, m):\n",
    "    lemmas = m.lemmatize(text)\n",
    "    return ''.join(lemmas)\n",
    "\n",
    "def sem_close_ARTM(model_artm):\n",
    "    sem = list()\n",
    "    for topic_name in model_artm.topic_names:\n",
    "#         print(topic_name + ': ')\n",
    "        temp = model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name]\n",
    "        sum_ = 0\n",
    "        for ind, word1 in enumerate(temp):\n",
    "            for word2 in temp:\n",
    "                try:\n",
    "                    sum_ += distance.cosine(w2v[word1], w2v[word2])\n",
    "                except:\n",
    "                    sum_ +=1.0\n",
    "        sem.append(sum_/len(temp))\n",
    "#    return sum(sem)/len(sem)\n",
    "    return sem\n",
    "\n",
    "def doc2vow(text):\n",
    "    text = text.split(sep='.')\n",
    "    temp_block = list()\n",
    "    for pred in text:\n",
    "        temp_block.append(' '.join(re.findall(pattern, pred)))\n",
    "    text = temp_block   \n",
    "    text = stemming(' . '.join(text), m).split(sep = '.')\n",
    "    \n",
    "    vow = str()\n",
    "    defdict = defaultdict(int)\n",
    "    new_text = str()\n",
    "    for word in''.join(text).replace('\\n', '').split():\n",
    "        if len(word)>2 and word not in stop_words:\n",
    "            defdict[word] += 1\n",
    "    vow += 'doc' + ' '\n",
    "    for key, elem in defdict.items():\n",
    "        vow += key + ':' + str(elem) + ' '\n",
    "    vow += '\\n'\n",
    "    with open('vow_test.txt', 'w+', encoding='utf-8') as file:\n",
    "        file.write(vow)\n",
    "    batch_vectorizer_test = artm.BatchVectorizer(data_path='vow_test.txt',\n",
    "                                        data_format='vowpal_wabbit',\n",
    "                                        target_folder='batch_test')\n",
    "    return batch_vectorizer_test\n",
    "\n",
    "def get_theta(model, batch):\n",
    "    return model.transform(batch_vectorizer=batch)\n",
    "\n",
    "def bestTopics(vector, topics):\n",
    "    new_vec = list()\n",
    "    for ind, item in enumerate(topics):\n",
    "        new_vec.append(vector[topics[ind]])\n",
    "    return new_vec\n",
    "\n",
    "def sem_close_Top2vec(model):\n",
    "    sem = list()\n",
    "    for i in range(model.get_num_topics()):\n",
    "        temp = model.topic_words[i][:6]\n",
    "        sum_ = 0\n",
    "        for ind, word1 in enumerate(temp):\n",
    "            for word2 in temp:\n",
    "                try:\n",
    "                    sum_ += distance.cosine(navec[word1], navec[word2])\n",
    "                except:\n",
    "                    sum_ +=0.7\n",
    "        sem.append(sum_/len(temp))\n",
    "#    return sum(sem)/len(sem)\n",
    "    return sem\n",
    "\n",
    "def topic_probs(doc, topic_vecs, k):\n",
    "    results = list()\n",
    "    ind = 0\n",
    "    for i in topic_vecs:\n",
    "        results.append(1/(distance.euclidean(doc, i) ** k))\n",
    "    return np.array(results)/sum(results)\n",
    "\n",
    "# def dist_top10(item, items_list):\n",
    "#     res = list()\n",
    "#     for i in tqdm(items_list):\n",
    "#         res.append(distance.cosine(item, list(i)))\n",
    "#     return sorted(zip(range(len(items_list)), res), key = lambda x: x[1])\n",
    "\n",
    "def dist_top10(item, items_list):\n",
    "    res = list()\n",
    "    for i in items_list:\n",
    "        res.append(distance.cosine(item, i))\n",
    "    return sorted(zip(range(len(res)), res), key = lambda x: x[1])[1:11]\n",
    "\n",
    "def prec(pred, k, num):\n",
    "    s = 0\n",
    "    for i in range(k):\n",
    "        if pred[i] < num + 11 and pred[i]>num:\n",
    "            s += 1\n",
    "    return s/k\n",
    "\n",
    "def clean_data(text):\n",
    "    text = text.split(sep='.')\n",
    "    temp_block = list()\n",
    "    for pred in text:\n",
    "        temp_block.append(' '.join(re.findall(pattern, pred)))\n",
    "    text = temp_block   \n",
    "    text = stemming(' . '.join(text), m).split(sep = '.')\n",
    "    new_text = str()\n",
    "    for word in ''.join(text).replace('\\n', '').split():\n",
    "        if len(word)>2 and word not in stop_words:\n",
    "            new_text += word + ' '\n",
    "    return new_text\n",
    "\n",
    "def create_dict(texts):\n",
    "    list_of_dicts = list()\n",
    "    dict_ = defaultdict(int)\n",
    "    for text in tqdm(texts):\n",
    "        list_of_dicts.append(defaultdict(int))\n",
    "        for word in text.split():\n",
    "            list_of_dicts[-1][word] += 1\n",
    "            dict_[word] += 1\n",
    "    return (list_of_dicts, dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\wiki_18k')\n",
    "\n",
    "texts = list()\n",
    "path = r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\wiki_18k'\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    with open(file, 'r', encoding='utf-8') as file_handler:\n",
    "        texts.append(file_handler.read())\n",
    "texts = list(set(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа')\n",
    "habr = pd.read_csv(\"habr_posts.csv\")\n",
    "habr = list(habr['text'].values)\n",
    "habr_texts = list()\n",
    "for i in tqdm(habr):\n",
    "    try:\n",
    "        if len(i.split())>500:\n",
    "            habr_texts.append(i)\n",
    "    except:\n",
    "        pass\n",
    "habr_texts = list(set(habr_texts))\n",
    "len(habr_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = list()\n",
    "all_texts = texts + habr_texts\n",
    "print(len(all_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(all_texts):\n",
    "    all_texts[i] = all_texts[i].split(sep='.')\n",
    "for i in tqdm(range(len(all_texts))):\n",
    "    temp_block = list()\n",
    "    for pred in all_texts[i]:\n",
    "        temp_block.append(' '.join(re.findall(pattern, pred)))\n",
    "    new_str = str()\n",
    "    for word in ' '.join(temp_block).split():\n",
    "        if word not in stop_words and len(word)>2:\n",
    "            new_str = new_str + word + ' '\n",
    "    all_texts[i] = new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(all_texts))):\n",
    "    temp_block = list() \n",
    "    all_texts[i] = stemming(' . '.join(all_texts[i]), m).split(sep = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('entry.pickle', 'wb') as f: pickle.dump(all_texts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vow_list = list()\n",
    "for i in tqdm(range(len(all_texts_clean))):\n",
    "    vow = str()\n",
    "    defdict = defaultdict(int)\n",
    "    new_text = str()\n",
    "    for word in all_texts_clean[i].replace('\\n', '').split():\n",
    "        if len(word)>2 and word not in stop_words:\n",
    "            defdict[word] += 1\n",
    "    vow += 'doc' + str(i) + ' '\n",
    "    for key, elem in defdict.items():\n",
    "        vow += key + ':' + str(elem) + ' '\n",
    "    vow_list.append(vow)\n",
    "#    vow += '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('vow.txt', 'w+', encoding='utf-8') as file_handler:\n",
    "    for i in tqdm(range(len(vow_list))):\n",
    "        file_handler.write(vow_list[i] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uci bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts, dict_ = create_dict(all_texts_clean)\n",
    "\n",
    "wordID = defaultdict(int)\n",
    "i = 1\n",
    "for key, value in list(dict_.items()):\n",
    "    wordID[key] = i\n",
    "    i += 1\n",
    "    \n",
    "triplet_list = list()\n",
    "for i, text in enumerate(all_texts_clean):\n",
    "    for word in text.split():\n",
    "        triplet_list.append((i, wordID[word], list_of_dicts[i][word]))\n",
    "len(triplet_list)\n",
    "\n",
    "with open('docword.UCI_dataset', mode = 'w+', encoding='utf-8') as file_handler:\n",
    "    file_handler.write(str(len(all_texts_clean)) + '\\n')\n",
    "    file_handler.write(str(len(dict_.keys())) + '\\n')  \n",
    "    sum = 0\n",
    "    for key, value in list(dict_.items()):\n",
    "        sum += value\n",
    "    file_handler.write(str(sum) + '\\n') \n",
    "    for item1, item2, item3 in tqdm(triplet_list):\n",
    "        file_handler.write(str(item1) + ' ' + str(item2) + ' ' + str(item3) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\vocab.UCI_dataset.txt', mode = 'w+', encoding='utf-8') as file_handler: \n",
    "    for key, value in list(dict_.items()): \n",
    "        file_handler.write(str(key) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI_data = str()\n",
    "with open('UCI_dataset', mode = 'r', encoding='utf-8') as file_handler:\n",
    "    UCI_data = file_handler.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20930/20930 [00:14<00:00, 1418.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 14057233/14057233 [00:34<00:00, 408126.76it/s]\n"
     ]
    }
   ],
   "source": [
    "list_of_dicts, dict_ = create_dict(new_doc)\n",
    "\n",
    "wordID = defaultdict(int)\n",
    "i = 1\n",
    "for key, value in list(dict_.items()):\n",
    "    wordID[key] = i\n",
    "    i += 1\n",
    "    \n",
    "triplet_list = list()\n",
    "for i, text in enumerate(new_doc):\n",
    "    for word in text.split():\n",
    "        triplet_list.append((i, wordID[word], list_of_dicts[i][word]))\n",
    "len(triplet_list)\n",
    "\n",
    "with open('docword_noise.UCI_dataset', mode = 'w+', encoding='utf-8') as file_handler:\n",
    "    file_handler.write(str(len(new_doc)) + '\\n')\n",
    "    file_handler.write(str(len(dict_.keys())) + '\\n')  \n",
    "    sum = 0\n",
    "    for key, value in list(dict_.items()):\n",
    "        sum += value\n",
    "    file_handler.write(str(sum) + '\\n') \n",
    "    for item1, item2, item3 in tqdm(triplet_list):\n",
    "        file_handler.write(str(item1) + ' ' + str(item2) + ' ' + str(item3) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\vocab_noise.UCI_dataset.txt', mode = 'w+', encoding='utf-8') as file_handler: \n",
    "    for key, value in list(dict_.items()): \n",
    "        file_handler.write(str(key) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI_data_noise = str()\n",
    "with open('UCI_dataset', mode = 'r', encoding='utf-8') as file_handler:\n",
    "    UCI_data = file_handler.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = sentences_1[:-550], sentences_1[-550:-330], sentences_1[-330:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "\n",
    "epoch_logger = EpochLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCDV:\n",
    "    \n",
    "    def __init__(self, data, w2v):\n",
    "        self.data = data\n",
    "        self.w2v = w2v\n",
    "        self.gmm_word = GaussianMixture(n_components=120,\n",
    "                                        max_iter = 50)\n",
    "        self.gmm_text = GaussianMixture(n_components=180, \n",
    "                                        max_iter = 80, \n",
    "                                        covariance_type = 'tied')\n",
    "        umap_default_args = {'n_neighbors': 30,\n",
    "             'n_components': 15,\n",
    "             'metric': 'cosine'}\n",
    "        self.n_features = 120\n",
    "        self.umap_word = UMAP(**umap_default_args)\n",
    "        self.umap_text = UMAP(**umap_default_args)\n",
    "        self.soft_clusters = None\n",
    "        self.soft_clustersKD = None\n",
    "        \n",
    "    def fit(self,\n",
    "            tune_umap_word = False, \n",
    "            tune_gmm_word = False, \n",
    "            tune_umap_text = False,\n",
    "            tune_gmm_text = False,  \n",
    "            val_data = None):\n",
    "        self.idfs = self._get_idfs()\n",
    "        self.keys= list()\n",
    "        self.word_vectors = list()\n",
    "        for i, _ in tqdm(self.idfs.items()):\n",
    "            try:\n",
    "                self.word_vectors.append(w2v[i])\n",
    "                self.keys.append(i)\n",
    "            except:\n",
    "                pass\n",
    "        if tune_umap_word:\n",
    "            self._tune_umap_word(val_data)\n",
    "        else:\n",
    "            self.umap_word.fit(np.array(self.word_vectors))\n",
    "        if tune_gmm_word:\n",
    "            self._tune_gmm_word(val_data)\n",
    "        else:\n",
    "            self.gmm_word.fit(self.umap_word.embedding_)\n",
    "        self.soft_clusters = self._get_soft_clusters()\n",
    "        self.soft_clustersKD = self._get_soft_clustersKD()\n",
    "        if tune_umap_text:\n",
    "            self._tune_umap_text(val_data)\n",
    "        for counter, elem in enumerate(self.umap_text.embedding_):\n",
    "            i = 1\n",
    "            for a in elem:\n",
    "                if math.isnan(a):\n",
    "                    self.umap_text.embedding_[counter] = [0]*length\n",
    "        if tune_gmm_text:\n",
    "            self._tune_gmm_text(val_data)\n",
    "        \n",
    "        text_vectors = list()\n",
    "        length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "        for elem in self.data:\n",
    "            sum_ = np.array([0]*length)\n",
    "            counter = 0\n",
    "            for word in elem.split():\n",
    "                try:\n",
    "                    sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                    counter = counter + 1\n",
    "                except:\n",
    "                    pass\n",
    "            text_vectors.append(sum_/counter)\n",
    "\n",
    "        counter = 0\n",
    "        i = 1\n",
    "        for counter, elem in enumerate(text_vectors):\n",
    "            i = 1\n",
    "            for a in elem:\n",
    "                if math.isnan(a):\n",
    "                    text_vectors[counter] = [0]*length\n",
    "        if tune_umap_text == False:\n",
    "            self.umap_text.fit(text_vectors)\n",
    "        for counter, elem in enumerate(self.umap_text.embedding_):\n",
    "            i = 1\n",
    "            for a in elem:\n",
    "                if math.isnan(a):\n",
    "                    self.umap_text.embedding_[counter] = [0]*length\n",
    "        if tune_gmm_text == False:\n",
    "            self.gmm_text.fit(self.umap_text.embedding_)\n",
    "    \n",
    "    def _get_soft_clusters(self):\n",
    "        pred = self.gmm_word.predict_proba(self.umap_word.embedding_)\n",
    "        soft_clusters = dict(zip(self.keys, pred))\n",
    "        return soft_clusters\n",
    "        \n",
    "    def _get_soft_clustersKD(self):\n",
    "        i = 0\n",
    "        soft_clustersKD = defaultdict(list)\n",
    "        for key in self.keys:\n",
    "            new_list = list()\n",
    "            for k in self.soft_clusters[key]:\n",
    "                new_list = new_list + list(np.array(self.umap_word.embedding_[i])*k)\n",
    "            soft_clustersKD[key] = np.array(new_list)*self.idfs[key]\n",
    "            i = i + 1\n",
    "        return soft_clustersKD\n",
    "        \n",
    "        \n",
    "    def _get_idfs(self):\n",
    "        tfv = TfidfVectorizer(min_df = 2)\n",
    "        tfidfmatrix_traindata = tfv.fit_transform(self.data)\n",
    "        featurenames = tfv.get_feature_names()\n",
    "        idf = tfv._tfidf.idf_\n",
    "        return dict(zip(featurenames, idf))        \n",
    "        \n",
    "    def _tune_umap_text(self, val_data):\n",
    "        print(\"tune umap text\\n\")\n",
    "        scores = list()        \n",
    "        text_vectors = list()\n",
    "        length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "        for elem in self.data:\n",
    "            sum_ = np.array([0]*length)\n",
    "            counter = 0\n",
    "            for word in elem.split():\n",
    "                try:\n",
    "                    sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                    counter = counter + 1\n",
    "                except:\n",
    "                    pass\n",
    "            text_vectors.append(sum_/counter)\n",
    "\n",
    "        counter = 0\n",
    "        i = 1\n",
    "        for counter, elem in enumerate(text_vectors):\n",
    "            i = 1\n",
    "            for a in elem:\n",
    "                if math.isnan(a):\n",
    "                    text_vectors[counter] = [0]*length\n",
    "                    \n",
    "        for i in tqdm(range(2, 15)):\n",
    "            umap_args = {'n_neighbors': 30,\n",
    "                 'n_components': i,\n",
    "                 'metric': 'cosine'}\n",
    "            self.umap_text = UMAP(**umap_args)\n",
    "            self.umap_text.fit(text_vectors)\n",
    "            for counter, elem in enumerate(self.umap_text.embedding_):\n",
    "                i = 1\n",
    "                for a in elem:\n",
    "                    if math.isnan(a):\n",
    "                        self.umap_text.embedding_[counter] = [0]*len(self.umap_text.embedding_[0])\n",
    "            self.gmm_text.fit(self.umap_text.embedding_)\n",
    "            va = self._compute_score_pred(val_data)\n",
    "            print(va)\n",
    "            scores.append(va)\n",
    "        param = sorted(zip(scores, range(2, 15)), \n",
    "                       key = lambda x: x[0], \n",
    "                       reverse = True)[0][1]\n",
    "        umap_args = {'n_neighbors': 30,\n",
    "                     'n_components': param,\n",
    "                     'metric': 'cosine'}\n",
    "        self.umap_text.fit(np.array(text_vectors))\n",
    "        \n",
    "    def _tune_umap_word(self, val_data):\n",
    "        print(\"tune umap word\\n\")\n",
    "        scores = list()\n",
    "        for i in tqdm(range(15, 16)):\n",
    "            umap_args = {'n_neighbors': 30,\n",
    "                 'n_components': i,\n",
    "                 'metric': 'cosine'}\n",
    "            self.umap_word = UMAP(**umap_args)\n",
    "            self.umap_word.fit(np.array(self.word_vectors))\n",
    "            self.gmm_word.fit(self.umap_word.embedding_)\n",
    "            self.soft_clusters = self._get_soft_clusters()\n",
    "            self.soft_clustersKD = self._get_soft_clustersKD() \n",
    "            \n",
    "            text_vectors = list()\n",
    "            length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "            for elem in self.data:\n",
    "                sum_ = np.array([0]*length)\n",
    "                counter = 0\n",
    "                for word in elem.split():\n",
    "                    try:\n",
    "                        sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                        counter = counter + 1\n",
    "                    except:\n",
    "                        pass\n",
    "                text_vectors.append(sum_/counter)\n",
    "                \n",
    "            counter = 0\n",
    "            i = 1\n",
    "            for counter, elem in enumerate(text_vectors):\n",
    "                i = 1\n",
    "                for a in elem:\n",
    "                    if math.isnan(a):\n",
    "                        text_vectors[counter] = [0]*length\n",
    "            self.umap_text.fit(text_vectors)\n",
    "            for counter, elem in enumerate(self.umap_text.embedding_):\n",
    "                i = 1\n",
    "                for a in elem:\n",
    "                    if math.isnan(a):\n",
    "                        self.umap_text.embedding_[counter] = [0]*length\n",
    "            self.gmm_text.fit(self.umap_text.embedding_)\n",
    "            print(\"brefore score\")\n",
    "            va = self._compute_score_pred(val_data)\n",
    "            print(va)\n",
    "            scores.append(va)\n",
    "        param = sorted(zip(scores, range(2, 15)), \n",
    "                       key = lambda x: x[0], \n",
    "                       reverse = True)[0][1]\n",
    "        umap_args = {'n_neighbors': 30,\n",
    "                     'n_components': param,\n",
    "                     'metric': 'cosine'}\n",
    "        self.umap_word.fit(np.array(self.word_vectors))\n",
    "            \n",
    "        \n",
    "    def _tune_gmm_word(self, val_data):\n",
    "        print(\"tune gmm word\\n\")\n",
    "        scores = list()\n",
    "        for i in tqdm(range(20, 140, 20)):\n",
    "            self.gmm_word = GaussianMixture(\n",
    "                n_components=i,\n",
    "                max_iter = 50)\n",
    "            self.n_features = i\n",
    "            self.gmm_word.fit(self.umap_word.embedding_)\n",
    "            self.soft_clusters = self._get_soft_clusters()\n",
    "            self.soft_clustersKD = self._get_soft_clustersKD() \n",
    "            \n",
    "            text_vectors = list()\n",
    "            length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "            for elem in self.data:\n",
    "                sum_ = np.array([0]*length)\n",
    "                counter = 0\n",
    "                for word in elem.split():\n",
    "                    try:\n",
    "                        sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                        counter = counter + 1\n",
    "                    except:\n",
    "                        pass\n",
    "                text_vectors.append(sum_/counter)\n",
    "                \n",
    "            counter = 0\n",
    "            i = 1\n",
    "            for counter, elem in enumerate(text_vectors):\n",
    "                i = 1\n",
    "                for a in elem:\n",
    "                    if math.isnan(a):\n",
    "                        text_vectors[counter] = [0]*length\n",
    "            self.umap_text.fit(text_vectors)\n",
    "            for counter, elem in enumerate(self.umap_text.embedding_):\n",
    "                i = 1\n",
    "                for a in elem:\n",
    "                    if math.isnan(a):\n",
    "                        self.umap_text.embedding_[counter] = [0]*length\n",
    "            self.gmm_text.fit(self.umap_text.embedding_)\n",
    "            va = self._compute_score_pred(val_data)\n",
    "            print(va)\n",
    "            scores.append(va)\n",
    "        param = sorted(zip(scores, range(20, 140, 20)), \n",
    "                       key = lambda x: x[0], \n",
    "                       reverse = True)[0][1]\n",
    "        self.gmm_word = GaussianMixture(\n",
    "            n_components=param,\n",
    "            max_iter = 50)\n",
    "        self.gmm_word.fit(self.umap_word.embedding_)\n",
    "        \n",
    "    def _tune_gmm_text(self, val_data):\n",
    "        print(\"tune gmm text\\n\")\n",
    "        scores = list()        \n",
    "        text_vectors = list()\n",
    "#        length = len(w2v['диск'])*len(self.soft_clustersKD[\"диск\"])\n",
    "        length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "        for elem in self.data:\n",
    "            sum_ = np.array([0]*length)\n",
    "            counter = 0\n",
    "            for word in elem.split():\n",
    "                try:\n",
    "                    sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                    counter = counter + 1\n",
    "                except:\n",
    "                    pass\n",
    "            text_vectors.append(sum_/counter)\n",
    "\n",
    "        counter = 0\n",
    "        i = 1\n",
    "        for counter, elem in enumerate(text_vectors):\n",
    "            i = 1\n",
    "            for a in elem:\n",
    "                if math.isnan(a):\n",
    "                    text_vectors[counter] = [0]*length\n",
    "                    \n",
    "        for i in tqdm(range(40, 220, 20)):\n",
    "            self.gmm_text = GaussianMixture(n_components=i, \n",
    "                                max_iter = 80, \n",
    "                                covariance_type = 'tied')\n",
    "            self.gmm_text.fit(self.umap_text.embedding_)\n",
    "            va = self._compute_score(val_data)\n",
    "            print(va)\n",
    "            scores.append(va)\n",
    "        param = sorted(zip(scores, range(40, 220, 20)), \n",
    "                       key = lambda x: x[0], \n",
    "                       reverse = True)[0][1]\n",
    "        self.gmm_text = GaussianMixture(n_components=param, \n",
    "                            max_iter = 80, \n",
    "                            covariance_type = 'tied')\n",
    "        self.gmm_text.fit(self.umap_text.embedding_)\n",
    "        \n",
    "    def _compute_score(self, val_data):\n",
    "        test_vectors = list()\n",
    "        length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "        for text in val_data:\n",
    "            sum_ = np.array([0]*length)\n",
    "            counter = 0\n",
    "            for word in text.split():\n",
    "                try:\n",
    "                    sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                    counter = counter + 1\n",
    "                except:\n",
    "                    pass\n",
    "            test_vectors.append(sum_/counter)\n",
    "        for counter, elem in enumerate(test_vectors):\n",
    "            for a in elem:\n",
    "                if (math.isnan(a)):\n",
    "                    test_vectors[counter] = [0]*length\n",
    "\n",
    "        pred_prob = self.umap_text.transform(test_vectors)\n",
    "        for counter, elem in enumerate(pred_prob):\n",
    "            for a in elem:\n",
    "                if math.isnan(a):\n",
    "                    pred_prob[counter] = [0]*len(self.umap_text.embedding_[0])\n",
    "        new_test_vecs = self.gmm_text.predict_proba(pred_prob)\n",
    "        \n",
    "        big_res = list()\n",
    "        for s in range(len(val_data) // 100):\n",
    "            results = list()\n",
    "            for i in [i*11 for i in range(10)]:\n",
    "                results.append(dist_top10(new_test_vecs[110*s:110*(s+1)][i], \n",
    "                                          new_test_vecs[110*s:110*(s+1)]))\n",
    "\n",
    "            leest = list()\n",
    "            for i in range(10):\n",
    "                leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "            big_res.append(sum(leest)/len(leest))\n",
    "        return sum(big_res)/len(big_res)\n",
    "    \n",
    "    def _compute_score_pred(self, val_data):\n",
    "        test_vectors = list()\n",
    "        \n",
    "        length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "        \n",
    "        for text in val_data:\n",
    "            sum_ = np.array([0]*length)\n",
    "            counter = 0\n",
    "            for word in text.split():\n",
    "                try:\n",
    "                    sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                    counter = counter + 1\n",
    "                except:\n",
    "                    pass\n",
    "            test_vectors.append(sum_/counter)\n",
    "        for counter, elem in enumerate(test_vectors):\n",
    "            for a in elem:\n",
    "                if (math.isnan(a)):\n",
    "                    test_vectors[counter] = [0]*length\n",
    "            \n",
    "\n",
    "        pred_prob = self.umap_text.transform(test_vectors)\n",
    "        \n",
    "        big_res = list()\n",
    "        for s in range(len(val_data) // 100):\n",
    "            results = list()\n",
    "            for i in [i*11 for i in range(10)]:\n",
    "                results.append(dist_top10(pred_prob[110*s:110*(s+1)][i], \n",
    "                                          pred_prob[110*s:110*(s+1)]))\n",
    "\n",
    "            leest = list()\n",
    "            for i in range(10):\n",
    "                leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "            big_res.append(sum(leest)/len(leest))\n",
    "        return sum(big_res)/len(big_res)\n",
    "    \n",
    "    def get_vectors(self, texts):\n",
    "        vectors = list()\n",
    "        length = len(self.umap_word.embedding_[0])*self.n_features\n",
    "        for text in texts:\n",
    "            sum_ = np.array([0]*length)\n",
    "            counter = 0\n",
    "            for word in text.split():\n",
    "                try:\n",
    "                    sum_ = sum_ + np.array(self.soft_clustersKD[word])\n",
    "                    counter = counter + 1\n",
    "                except:\n",
    "                    pass\n",
    "            vectors.append(sum_/counter)\n",
    "        for counter, elem in enumerate(vectors):\n",
    "            for a in elem:\n",
    "                if (math.isnan(a)):\n",
    "                    vectors[counter] = [0]*length\n",
    "        pred_prob = self.umap_text.transform(vectors)\n",
    "        new_test_vecs_1 = self.gmm_text.predict_proba(pred_prob)\n",
    "        return new_test_vecs_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastTextKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "w2v = FastTextKeyedVectors.load(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\213\\\\' + 'model.model')\n",
    "#w2v = KeyedVectors.load(model_path + 'word2vec_hard_06.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\sen_1', 'rb') as f:\n",
    "    sentences_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdv_dr = SCDV(train, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\umap_word', 'rb') as f: \n",
    "    umap_word = pickle.load(f)\n",
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\gmm_word', 'rb') as f: \n",
    "    gmm_word = pickle.load(f)\n",
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\soft_clusters', 'rb') as f: \n",
    "    soft_clusters = pickle.load(f)\n",
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\soft_clustersKD', 'rb') as f: \n",
    "    soft_clustersKD = pickle.load(f)\n",
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\umap_text', 'rb') as f: \n",
    "    umap_text = pickle.load(f)\n",
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\gmm_text', 'rb') as f: \n",
    "    gmm_text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdv.soft_clusters = soft_clusters\n",
    "scdv.soft_clustersKD = soft_clustersKD\n",
    "scdv.umap_text = umap_text\n",
    "scdv.gmm_text = gmm_text\n",
    "scdv.umap_word = umap_word\n",
    "scdv.gmm_word = gmm_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 109531/109531 [00:08<00:00, 13084.00it/s]\n"
     ]
    }
   ],
   "source": [
    "scdv.fit(False, False, False, False, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdv.w2v = w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\scdv_obj', 'wb') as f: \n",
    "    pickle.dump(scdv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\scdv_obj', 'rb') as f: \n",
    "    scdv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDV without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdv_noise = SCDV(new_doc, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 87869/87869 [00:52<00:00, 1676.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune umap text\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                           | 1/13 [02:12<26:30, 132.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▊                                                                      | 2/13 [03:02<15:23, 83.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|███████████████████▏                                                               | 3/13 [04:13<13:01, 78.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▌                                                         | 4/13 [05:11<10:30, 70.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▉                                                   | 5/13 [06:10<08:49, 66.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|██████████████████████████████████████▎                                            | 6/13 [07:37<08:32, 73.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████▋                                      | 7/13 [08:43<07:05, 70.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████████                                | 8/13 [10:23<06:40, 80.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████▍                         | 9/13 [11:42<05:19, 79.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████                   | 10/13 [13:16<04:12, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 11/13 [14:49<02:53, 86.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▋      | 12/13 [16:23<01:29, 89.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [18:02<00:00, 83.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune gmm text\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▎                                                                          | 1/9 [00:27<03:41, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▋                                                                 | 2/9 [00:54<03:08, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 3/9 [01:31<03:10, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████████▎                                              | 4/9 [02:24<03:20, 40.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16799999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▎                                              | 4/9 [03:38<04:32, 54.57s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-074e4ca958ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscdv_noise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-73-150577ab1d06>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, tune_umap_word, tune_gmm_word, tune_umap_text, tune_gmm_text, val_data)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtune_gmm_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tune_gmm_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-150577ab1d06>\u001b[0m in \u001b[0;36m_tune_gmm_text\u001b[1;34m(self, val_data)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgmm_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mumap_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0mva\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-150577ab1d06>\u001b[0m in \u001b[0;36m_compute_score\u001b[1;34m(self, val_data)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mpred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mumap_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\umap\\umap_.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_metric\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"euclidean\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2779\u001b[1;33m             embedding = optimize_layout_euclidean(\n\u001b[0m\u001b[0;32m   2780\u001b[0m                 \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\umap\\layouts.py\u001b[0m in \u001b[0;36moptimize_layout_euclidean\u001b[1;34m(head_embedding, tail_embedding, head, tail, n_epochs, n_vertices, epochs_per_sample, a, b, rng_state, gamma, initial_alpha, negative_sample_rate, parallel, verbose, densmap, densmap_kwds)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         optimize_fn(\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0mhead_embedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m                 \u001b[0mcres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_cached\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_cached\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_core\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         cres = compiler.compile_extra(self.targetdescr.typing_context,\n\u001b[0m\u001b[0;32m    106\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargetdescr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    626\u001b[0m                               args, return_type, flags, locals)\n\u001b[1;32m--> 627\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mExtractByteCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\untyped_passes.py\u001b[0m in \u001b[0;36mrun_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfunc_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'func_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mbc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytecode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDUMP_BYTECODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\bytecode.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func_id)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# A map of {offset: ByteCodeInst}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mByteCodeIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_lineno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\bytecode.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnextoffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_opcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         return offset, ByteCodeInst(offset=offset, opcode=opcode, arg=arg,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\bytecode.py\u001b[0m in \u001b[0;36m_fetch_opcode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fetch_opcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\bytecode.py\u001b[0m in \u001b[0;36m_patched_opargs\u001b[1;34m(bc_stream)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;31m# Adjust bytecode offset for the rest of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnextoffset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbc_stream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[1;31m# If the opcode has an absolute jump target, adjust it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\bytecode.py\u001b[0m in \u001b[0;36m_unpack_opargs\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mCODE_LEN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mHAVE_ARGUMENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[1;31m# (5 blanks lines) where none should be returned.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_fixed_getinnerframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36m_fixed_getinnerframes\u001b[1;34m(etb, context, tb_offset)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m     \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix_frame_records_filenames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetinnerframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m     \u001b[1;31m# If the error is at the console, don't build any context, since it would\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetinnerframes\u001b[1;34m(tb, context)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1503\u001b[1;33m         \u001b[0mframeinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb_frame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1435\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                                tb_offset)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[0mhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong_header\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m         \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[0minspect_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mostream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m             \u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nUnfortunately, your original traceback can not be constructed.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mprint_exc\u001b[1;34m(limit, file, chain)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;34m\"\"\"Shorthand for 'print_exception(*sys.exc_info(), limit, file)'.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mprint_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mprint_exception\u001b[1;34m(etype, value, tb, limit, file, chain)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     for line in TracebackException(\n\u001b[0m\u001b[0;32m    104\u001b[0m             type(value), value, tb, limit=limit).format(chain=chain):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, _seen)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;31m# TODO: locals.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         self.stack = StackSummary.extract(\n\u001b[0m\u001b[0;32m    510\u001b[0m             \u001b[0mwalk_tb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlookup_lines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2057\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, exc_tuple)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \"\"\"\n\u001b[0;32m   2003\u001b[0m         \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_exc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2004\u001b[1;33m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mformat_exception_only\u001b[1;34m(etype, value)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTracebackException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, _seen)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36m_load_lines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36m_load_lines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;34m\"\"\"Private API. force all lines in the stack to be loaded.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlineno\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mclearcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\tokenize.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_buffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\tokenize.py\u001b[0m in \u001b[0;36mdetect_encoding\u001b[1;34m(readline)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m     \u001b[0mfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_or_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBOM_UTF8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mbom_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\tokenize.py\u001b[0m in \u001b[0;36mread_or_stop\u001b[1;34m()\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_or_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scdv_noise.fit(False, False, True, True, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.dictionary.Dictionary"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа')\n",
    "data_path = r''\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path='', data_format='bow_uci',\n",
    "                                        collection_name='UCI_dataset', target_folder='kos_batches')\n",
    "dictionary = batch_vectorizer.dictionary\n",
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = batch_vectorizer.dictionary\n",
    "score_ret = list()\n",
    "scores_1 = list()\n",
    "for T in tqdm(range(30, 310, 20)):\n",
    "    topic_names = ['topic_{}'.format(i) for i in range(T)]\n",
    "    model_artm = artm.ARTM(topic_names=topic_names, cache_theta=True, \n",
    "                           scores=[artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary)], \n",
    "                           regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.15)])\n",
    "    model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "    model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "    model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
    "                                                      probability_mass_threshold=0.3))\n",
    "    model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
    "    model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))\n",
    "    model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "    model_artm.initialize(dictionary=dictionary)\n",
    "    model_artm.num_document_passes = 1\n",
    "    model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=8)\n",
    "    \n",
    "    s = list()\n",
    "    for ind in range(3, 5):\n",
    "        theta_list_test = list()\n",
    "        for i in (test_data[110*ind:(ind+1)*110]):\n",
    "            theta_list_test.append(get_theta(model_artm, doc2vow(i)))\n",
    "        results = list()\n",
    "        for i in [i*11 for i in range(5)]:\n",
    "            results.append(dist_top10(theta_list_test[i], theta_list_test))\n",
    "        leest = list()\n",
    "        for i in range(5):\n",
    "            leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "        s.append(sum(leest)/len(leest))\n",
    "    score_ret.append(sum(s)/len(s))\n",
    "    print(sum(s)/len(s))\n",
    "         \n",
    "#     model_artm.fit_online(batch_vectorizer=batch_vectorizer, asynchronous=True)\n",
    "    scores_1.append((T, model_artm.score_tracker['PerplexityScore'].last_value, sem_close_ARTM(model_artm)))\n",
    "#    print((T, model_artm.score_tracker['PerplexityScore'].last_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = batch_vectorizer.dictionary\n",
    "T = 90\n",
    "topic_names = ['topic_{}'.format(i) for i in range(T)]\n",
    "model_artm = artm.ARTM(topic_names=topic_names, cache_theta=True, \n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary)], \n",
    "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.15)])\n",
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
    "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))\n",
    "model_artm.initialize(dictionary=dictionary)\n",
    "# model_artm.num_document_passes = 3\n",
    "# model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "# #    model_artm.fit_online(batch_vectorizer=batch_vectorizer, asynchronous=True)\n",
    "# print(model_artm.score_tracker['PerplexityScore'].last_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_artm.save(\"model_artm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\")\n",
    "model_artm.load(r'model_artm')\n",
    "os.chdir(r\"C:\\Users\\vdtri\\Documents\\ВКР\\Программа\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TopTokensScore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2e32576ca842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopic_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_artm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_artm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_tracker\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TopTokensScore'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'TopTokensScore'"
     ]
    }
   ],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print(topic_name + ': ')\n",
    "    print(model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.dictionary.Dictionary"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа')\n",
    "data_path = r''\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path='', data_format='bow_uci',\n",
    "                                        collection_name='UCI_dataset_noise', target_folder='kos_batches_noise')\n",
    "dictionary = batch_vectorizer.dictionary\n",
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307.79754638671875\n"
     ]
    }
   ],
   "source": [
    "dictionary = batch_vectorizer.dictionary\n",
    "T = 90\n",
    "topic_names = ['topic_{}'.format(i) for i in range(T)]\n",
    "model_artm_noise = artm.ARTM(topic_names=topic_names, cache_theta=True, \n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary)], \n",
    "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.15)])\n",
    "model_artm_noise.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_artm_noise.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm_noise.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "model_artm_noise.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
    "model_artm_noise.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))\n",
    "model_artm_noise.initialize(dictionary=dictionary)\n",
    "model_artm_noise.num_document_passes = 3\n",
    "model_artm_noise.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "#    model_artm.fit_online(batch_vectorizer=batch_vectorizer, asynchronous=True)\n",
    "print(model_artm_noise.score_tracker['PerplexityScore'].last_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm_noise.save(\"model_artm_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\")model_artm.save(\"model_artm_noise\")\n",
    "model_artm.load(\"model_artm_noise\")\n",
    "os.chdir(r\"C:\\Users\\vdtri\\Documents\\ВКР\\Программа\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import top2vec\n",
    "from top2vec import Top2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_args = {'n_neighbors': 30,\n",
    "             'n_components': 15,\n",
    "             'metric': 'cosine'}\n",
    "model_noise = Top2Vec(documents=all_texts_clean, min_count=0, speed=\"learn\", workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Top2Vec.load(model_path + 'top2vec_deep.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "class_0 = list()\n",
    "class_0_vectors = list()\n",
    "for i in range(len(model._get_document_vectors())):\n",
    "    if (model.get_documents_topics([i])[0][0] == num):\n",
    "        class_0.append(i)\n",
    "\n",
    "for i, val in enumerate(model._get_document_vectors()):\n",
    "    if (i in class_0):\n",
    "        class_0_vectors.append(np.array(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-22 09:51:01,763 - top2vec - INFO - Pre-processing documents for training\n",
      "2021-04-22 09:52:00,423 - top2vec - INFO - Creating joint document/word embedding\n",
      "2021-04-22 10:43:44,698 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2021-04-22 10:43:54,336 - top2vec - INFO - Finding dense areas of documents\n",
      "2021-04-22 10:43:56,281 - top2vec - INFO - Finding topics\n"
     ]
    }
   ],
   "source": [
    "umap_args = {'n_neighbors': 30,\n",
    "             'n_components': 15,\n",
    "             'metric': 'cosine'}\n",
    "model_noise = Top2Vec(documents=new_doc, min_count=0, speed=\"learn\", workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noise.save(\"model_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noise= Top2Vec.load(model_path  + \"model_noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = model._get_document_vectors()[:-550]\n",
    "hdbscan_args = {'min_cluster_size': 5,\n",
    "                'metric': 'euclidean',\n",
    "                'cluster_selection_method': 'eom', \n",
    "                'min_samples':1}\n",
    "umap_args = {'n_neighbors': 15,\n",
    "             'n_components': 5,\n",
    "             'metric': 'cosine'}\n",
    "\n",
    "umap_model = UMAP(**umap_args).fit(model._get_document_vectors(norm=False))\n",
    "cluster = hdbscan.HDBSCAN(**hdbscan_args).fit(umap_model.embedding_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_without_noise = list(zip(cluster.labels_, sentences_1[:-550]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = list()\n",
    "for i, j in doc_without_noise:\n",
    "    if i != -1:\n",
    "        new_doc.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDV with ARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "\n",
    "tfv = TfidfVectorizer(min_df = 2)\n",
    "tfidfmatrix_traindata = tfv.fit_transform(sentences_1)\n",
    "featurenames = tfv.get_feature_names()\n",
    "idf = tfv._tfidf.idf_\n",
    "\n",
    "idfs = dict(zip(featurenames, idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = model_artm.get_phi()\n",
    "n_wt = model_artm.get_phi(model_name=model_artm.model_nwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:00, 133.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 213091/213091 [03:42<00:00, 957.42it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "n_t = list([0]*90)\n",
    "p_w = list()\n",
    "p_t = list([0]*90)\n",
    "for topic_ind, topic in tqdm(enumerate(['topic_' + str(i) for i in range(90)])):\n",
    "    val = n_wt.iloc[:, topic_ind].sum()\n",
    "    n_t[topic_ind] = val\n",
    "    n = n + val\n",
    "    \n",
    "for i in range(90):\n",
    "    p_t[i] = n_t[i]/n\n",
    "\n",
    "for i in tqdm(range(len(phi.T.keys()))):\n",
    "    val = 0\n",
    "    if phi.iloc[i, :].sum() == 0:\n",
    "        p_w.append(0)\n",
    "        continue\n",
    "    for ind in range(90):\n",
    "        val = val + phi.iloc[i, ind]*p_t[ind]\n",
    "    p_w.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = list()\n",
    "# for k in tqdm(range(20, 60, 5)):\n",
    "#     soft_clustersARTM = defaultdict(list)\n",
    "#     for ind, key in enumerate(phi.T.keys()):\n",
    "#         if p_w[ind] == 0:\n",
    "#             continue\n",
    "#         temp_list = list()\n",
    "#         for i in range(90):\n",
    "#             temp_list.append(phi.iloc[ind, i]*p_t[i]/p_w[ind])\n",
    "#         if np.max(temp_list)>k/100:\n",
    "#             soft_clustersARTM[key[1]] = temp_list\n",
    "            \n",
    "#     new_soft = list()\n",
    "#     print(len(soft_clustersARTM.keys()))\n",
    "#     for i, j in soft_clustersARTM.items():\n",
    "#         if i not in idfs.keys():\n",
    "#             new_soft.append(i)\n",
    "\n",
    "#     for i in new_soft:\n",
    "#         soft_clustersARTM.pop(i)\n",
    "#     len(soft_clustersARTM.keys())\n",
    "            \n",
    "#     soft_clustersKD_ARTM = defaultdict(list)\n",
    "#     umap_args = {'n_neighbors': 30,\n",
    "#              'n_components': 15,\n",
    "#              'metric': 'cosine'}\n",
    "#     umap_word = UMAP(**umap_args)\n",
    "#     umap_word.fit([w2v[i] for i in soft_clustersARTM.keys() if i in w2v.vocab.keys()])\n",
    "#     keys = [i for i in soft_clustersARTM.keys() if i in w2v.vocab.keys()]\n",
    "#     embed = umap_word.embedding_\n",
    "#     i=0\n",
    "#     for key in keys:\n",
    "#         new_list = list()\n",
    "#         for k in soft_clustersARTM[key]:\n",
    "#             new_list = new_list + list(np.array(embed[i])*k)\n",
    "#         try:\n",
    "#             soft_clustersKD_ARTM[key] = np.array(new_list)*idfs[key]\n",
    "#         except:\n",
    "#             pass\n",
    "#         i = i + 1\n",
    "        \n",
    "#     big_res = list()\n",
    "#     for s in range(5):\n",
    "#         test_vectores = list()\n",
    "#         for elem in test_data[110*s:110*(s+1)]:\n",
    "#             sum_ = np.array([0]*soft_clustersKD_ARTM['регрессия'])\n",
    "#             counter = 0\n",
    "#             for word in elem.split():\n",
    "#                 try:\n",
    "#                     sum_ = sum_ + np.array(soft_clustersKD_ARTM[word])\n",
    "#                     counter = counter + 1\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             test_vectores.append(sum_/counter)\n",
    "\n",
    "#         results = list()\n",
    "#         for i in [i*11 for i in range(10)]:\n",
    "#             results.append(dist_top10(test_vectores[i], test_vectores))\n",
    "\n",
    "#         leest = list()\n",
    "#         for i in range(10):\n",
    "#             leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "#         big_res.append(sum(leest)/len(leest))\n",
    "#     scores.append(sum(big_res)/len(big_res))\n",
    "#     print(big_res)\n",
    "#     print(sum(big_res)/len(big_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "artm_items = soft_clustersARTM.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212880"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63478"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_clustersARTM = defaultdict(list)\n",
    "for ind, key in enumerate(phi.T.keys()):\n",
    "    if p_w[ind] == 0:\n",
    "        continue\n",
    "    temp_list = list()\n",
    "    for i in range(90):\n",
    "        temp_list.append(phi.iloc[ind, i]*p_t[i]/p_w[ind])\n",
    "    if np.max(temp_list)>50/100:\n",
    "        soft_clustersARTM[key[1]] = temp_list\n",
    "\n",
    "new_soft = list()\n",
    "print(len(soft_clustersARTM.keys()))\n",
    "for i, j in soft_clustersARTM.items():\n",
    "    if i not in idfs.keys():\n",
    "        new_soft.append(i)\n",
    "\n",
    "for i in new_soft:\n",
    "    soft_clustersARTM.pop(i)\n",
    "len(soft_clustersARTM.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soft_clustersKD_ARTM['регрессия'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_clustersKD_ARTM_new = defaultdict(list)\n",
    "umap_args = {'n_neighbors': 30,\n",
    "         'n_components': 2,\n",
    "         'metric': 'cosine'}\n",
    "umap_word = UMAP(**umap_args)\n",
    "keys = [i for i in soft_clustersARTM.keys() if i in w2v.vocab.keys()]\n",
    "i=0\n",
    "for key in keys:\n",
    "    new_list = list()\n",
    "    try:\n",
    "        soft_clustersKD_ARTM_new[key] = np.array(soft_clustersARTM[key])*idfs[key]\n",
    "    except:\n",
    "        pass\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 32121/32121 [01:23<00:00, 383.73it/s]\n"
     ]
    }
   ],
   "source": [
    "text_vectores = list()\n",
    "length = len(soft_clustersKD_ARTM['регрессия'])\n",
    "for elem in tqdm(sentences_1):\n",
    "    sum_ = np.array([0]*length)\n",
    "    counter = 0\n",
    "    for word in elem.split():\n",
    "        try:\n",
    "            sum_ = sum_ + np.array(soft_clustersKD_ARTM[word])\n",
    "            counter = counter + 1\n",
    "        except:\n",
    "            pass\n",
    "    text_vectores.append(sum_/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dict = defaultdict(list)\n",
    "for elem in text_vectores:\n",
    "    for i in range(90):\n",
    "        items_dict[i].append(elem[2*i:2*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:16<00:00,  5.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, j in tqdm(items_dict.items()):\n",
    "#     print(\"______________\")\n",
    "    amount = len(items_dict[i])\n",
    "#     print(amount)\n",
    "    for s in np.arange(0, 15, 0.1):\n",
    "        counter = 0\n",
    "        temp = list()\n",
    "        for elem in j:\n",
    "            if (abs(elem[0])<s and abs(elem[1])<s):\n",
    "                counter = counter + 1\n",
    "            if (abs(elem[0])>s and abs(elem[1])>s):\n",
    "                temp.append(elem)\n",
    "        if counter/amount > 0.7:\n",
    "#             print(counter)\n",
    "#             print(s)\n",
    "            items_dict[i] = temp\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:05<00:00, 17.82it/s]\n"
     ]
    }
   ],
   "source": [
    "centers = list()\n",
    "for i, j in tqdm(items_dict.items()):\n",
    "    temp = zip(range(len(sentences_1)), [abs(t[0]) + abs(t[1]) for t in j])\n",
    "    ind = sorted(temp, key = lambda x: x[1], reverse=True)[5][0]\n",
    "    centers.append(j[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([abs(t[0]) + abs(t[1]) for t in j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centers = list()\n",
    "for i, j in items_dict.items():\n",
    "    centers.append(sum(items_dict[i])/len(items_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(90):\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "def plot_fn(xpoints=None, ypoints=None):\n",
    "    ax.scatter(xpoints, ypoints)\n",
    "    plt.show()\n",
    "plot_fn([xy[0] for xy in items_dict[i]], [xy[1] for xy in items_dict[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "def plot_fn(xpoints=None, ypoints=None):\n",
    "    ax.scatter(xpoints, ypoints)\n",
    "    plt.show()\n",
    "plot_fn([xy[0] for xy in centers], [xy[1] for xy in centers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25354161, 2.27796607])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(items_dict[1])/len(items_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scdv_artm(item, centers):\n",
    "    soft = list()\n",
    "    for s in range(90):\n",
    "        soft.append(1/(distance.euclidean(item[2*s:2*(s+1)], centers[s]) ** 2))\n",
    "    return np.array(soft)/sum(soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 0.23342948642517786)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(range(90), test_vectores[8]), key = lambda x: x[1], reverse = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 110/110 [00:00<00:00, 150.25it/s]\n"
     ]
    }
   ],
   "source": [
    "length = len(soft_clustersKD_ARTM_new['регрессия'])\n",
    "\n",
    "for elem in tqdm(test_data[110*0:110*(0+1)]):\n",
    "    sum_ = np.array([0]*length)\n",
    "    counter = 0\n",
    "    for word in elem.split():\n",
    "        try:\n",
    "            sum_ = sum_ + np.array(soft_clustersKD_ARTM_new[word])\n",
    "            counter = counter + 1\n",
    "        except:\n",
    "            pass\n",
    "    if counter != 0:\n",
    "        test_vectores.append(sum_/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vectores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 550/550 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [09:25<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path_to_prog + 'For_test_new')\n",
    "test_data = list()\n",
    "texts_1 = list()\n",
    "texts_2 = list()\n",
    "i = 0\n",
    "for item in sorted(os.listdir(), key = lambda x: int(x.split(sep = '.')[0])):\n",
    "    with open(item, 'r+', encoding='utf-8') as file:\n",
    "        texts_1.append(file.read())\n",
    "\n",
    "def_dict1 = defaultdict(str)\n",
    "for i in tqdm(range(len(texts_1))):\n",
    "    def_dict1[i] += texts_1[i]\n",
    "\n",
    "for text in tqdm(texts_1):\n",
    "    test_data.append(clean_data(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\vdtri\\Documents\\ВКР\\Программа\\models\\SCDV\\sen_1', 'rb') as f:\n",
    "    sentences_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = sentences_1[-550:]\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433333333333333\n"
     ]
    }
   ],
   "source": [
    "big_res = list()\n",
    "for s in range(3):\n",
    "    test_vectores = scdv.get_vectors(test_data[110*s:110*(s+1)])\n",
    "\n",
    "    results = list()\n",
    "    for i in [i*11 for i in range(10)]:\n",
    "        results.append(dist_top10(test_vectores[i], test_vectores))\n",
    "\n",
    "    leest = list()\n",
    "    for i in range(10):\n",
    "        leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "    big_res.append(sum(leest)/len(leest))\n",
    "#    print(sum(leest)/len(leest))\n",
    "print(sum(big_res)/ len(big_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_vectores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [07:59<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "theta_list_test = list()\n",
    "for i in tqdm(test_data):\n",
    "    theta_list_test.append(get_theta(model_artm, doc2vow(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "big_res = list()\n",
    "for s in range(3):\n",
    "    test_vectores = list()\n",
    "    elem = theta_list_test[110*s:110*(s+1)]\n",
    "\n",
    "    results = list()\n",
    "    for i in [i*11 for i in range(10)]:\n",
    "        results.append(dist_top10(elem[i], elem))\n",
    "\n",
    "    leest = list()\n",
    "    for i in range(10):\n",
    "        leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "    big_res.append(sum(leest)/len(leest))\n",
    "print(sum(big_res)/ len(big_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [07:52<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "theta_list_test = list()\n",
    "for i in tqdm(test_data):\n",
    "    theta_list_test.append(get_theta(model_artm_noise, doc2vow(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7659999999999999\n"
     ]
    }
   ],
   "source": [
    "big_res = list()\n",
    "for s in range(5):\n",
    "    test_vectores = list()\n",
    "    elem = theta_list_test[110*s:110*(s+1)]\n",
    "\n",
    "    results = list()\n",
    "    for i in [i*11 for i in range(10)]:\n",
    "        results.append(dist_top10(elem[i], elem))\n",
    "\n",
    "    leest = list()\n",
    "    for i in range(10):\n",
    "        leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "    big_res.append(sum(leest)/len(leest))\n",
    "print(sum(big_res)/ len(big_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs = list()\n",
    "model.add_documents(test_data)\n",
    "test_vecs = model._get_document_vectors()[-550:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 136.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:01, 349.81it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_vectors = model.topic_vectors\n",
    "doc_vectors = model._get_document_vectors()[-550:]\n",
    "print(len(topic_vectors[0]))\n",
    "new_test_vecs = list()\n",
    "for ind, item in tqdm(enumerate(doc_vectors)):\n",
    "    new_test_vecs.append(topic_probs(doc_vectors[ind], topic_vectors, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "big_res = list()\n",
    "for s in range(3):\n",
    "    test_vectores = list()\n",
    "    elem = new_test_vecs[110*s:110*(s+1)]\n",
    "\n",
    "    results = list()\n",
    "    for i in [i*11 for i in range(10)]:\n",
    "        results.append(dist_top10(elem[i], elem))\n",
    "\n",
    "    leest = list()\n",
    "    for i in range(10):\n",
    "        leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "    big_res.append(sum(leest)/len(leest))\n",
    "print(sum(big_res)/ len(big_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs = list()\n",
    "model_noise.add_documents(test_data)\n",
    "test_vecs = model_noise._get_document_vectors()[-550:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 250.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:01, 317.76it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_vectors = model_noise.topic_vectors\n",
    "doc_vectors = model_noise._get_document_vectors()[-550:]\n",
    "print(len(topic_vectors[0]))\n",
    "new_test_vecs = list()\n",
    "for ind, item in tqdm(enumerate(doc_vectors)):\n",
    "    new_test_vecs.append(topic_probs(doc_vectors[ind], topic_vectors, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833333333333332\n"
     ]
    }
   ],
   "source": [
    "big_res = list()\n",
    "for s in range(3):\n",
    "    test_vectores = list()\n",
    "    elem = new_test_vecs[110*s:110*(s+1)]\n",
    "\n",
    "    results = list()\n",
    "    for i in [i*11 for i in range(10)]:\n",
    "        results.append(dist_top10(elem[i], elem))\n",
    "\n",
    "    leest = list()\n",
    "    for i in range(10):\n",
    "        leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "    big_res.append(sum(leest)/len(leest))\n",
    "print(sum(big_res)/ len(big_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDV with ARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "big_res = list()\n",
    "for s in range(3):\n",
    "    test_vectores = list()\n",
    "    length = len(soft_clustersKD_ARTM_new['регрессия'])\n",
    "    for elem in test_data[110*s:110*(s+1)]:\n",
    "        sum_ = np.array([0]*length)\n",
    "        counter = 0\n",
    "        for word in elem.split():\n",
    "            try:\n",
    "                sum_ = sum_ + np.array(soft_clustersKD_ARTM_new[word])\n",
    "                counter = counter + 1\n",
    "            except:\n",
    "                pass\n",
    "        test_vectores.append(sum_/counter)\n",
    "        \n",
    "    for ind, elem in enumerate(test_vectores):\n",
    "        test_vectores[ind] = elem/sum(elem)\n",
    "    results = list()\n",
    "    for i in [i*11 for i in range(10)]:\n",
    "        results.append(dist_top10(test_vectores[i], test_vectores))\n",
    "    leest = list()\n",
    "    for i in range(10):\n",
    "        leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))\n",
    "    big_res.append(sum(leest)/len(leest))\n",
    "print(sum(big_res)/ len(big_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soft_clustersKD_ARTM['регрессия'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "for text in sentences_1:\n",
    "    if len(text.split())<5000:\n",
    "        data.append(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAJNCAYAAACBe1nxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3df9RtdX0f+PdH8AdRiFDBIJBctKSpmojxSmyNjomZiJKKzYqRZlKIixlmXDSx7STppckkJh0m2Eycxlhpib+w/iAsE5e3Ek0YGk2mi4AXQX6GAkrkBhTUmqCtGOAzf5x94/HyPJdz4Z77fM9zX6+1ztp7f8/e+3y+7AXPm+/+Vd0dAADG85iNLgAAgLUJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwqIM3uoBlecpTntJbtmzZ6DIAAB7WVVdd9YXuPnL39k0b1LZs2ZIdO3ZsdBkAAA+rqv58rXanPgEABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIM6eKML4JHZsu2Shda7/bxTllwJALAsRtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBLTWoVdWTq+oDVfVnVXVTVf29qjqiqi6tqlum6eFz659TVbdW1c1V9bK59udV1XXTd2+uqlpm3QAAI1j2iNpvJvlod39XkuckuSnJtiSXdfcJSS6bllNVz0xyWpJnJTk5yVur6qBpP+cnOSvJCdPn5CXXDQCw4ZYW1KrqsCQvTvL2JOnur3f3l5OcmuTCabULk7xqmj81yUXdfV93fybJrUlOqqqjkxzW3Zd3dyd599w2AACb1jJH1J6e5J4k76yqq6vqbVX1xCRP7e67kmSaHjWtf0ySO+a23zm1HTPN794OALCpLTOoHZzke5Oc393PTfLVTKc517HWdWe9h/aH7qDqrKraUVU77rnnnr2tFwBgKMsMajuT7OzuK6blD2QW3D4/nc7MNL17bv3j5rY/NsmdU/uxa7Q/RHdf0N1bu3vrkUceuc86AgCwEZYW1Lr7c0nuqKq/MzW9NMmNSbYnOWNqOyPJh6b57UlOq6rHV9Xxmd00cOV0evTeqnrBdLfn6XPbAABsWgcvef8/neS9VfW4JJ9O8trMwuHFVXVmks8meXWSdPcNVXVxZmHu/iRnd/cD035el+RdSQ5J8pHpAwCwqS01qHX3NUm2rvHVS9dZ/9wk567RviPJs/dtdQAAY/NmAgCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKCWGtSq6vaquq6qrqmqHVPbEVV1aVXdMk0Pn1v/nKq6tapurqqXzbU/b9rPrVX15qqqZdYNADCC/TGi9gPdfWJ3b52WtyW5rLtPSHLZtJyqemaS05I8K8nJSd5aVQdN25yf5KwkJ0yfk/dD3QAAG2ojTn2emuTCaf7CJK+aa7+ou+/r7s8kuTXJSVV1dJLDuvvy7u4k757bBgBg01p2UOskf1hVV1XVWVPbU7v7riSZpkdN7cckuWNu251T2zHT/O7tAACb2sFL3v8Lu/vOqjoqyaVV9Wd7WHet6856D+0P3cEsDJ6VJN/+7d++t7UCAAxlqSNq3X3nNL07yQeTnJTk89PpzEzTu6fVdyY5bm7zY5PcObUfu0b7Wr93QXdv7e6tRx555L7sCgDAfre0oFZVT6yqQ3fNJ/nhJNcn2Z7kjGm1M5J8aJrfnuS0qnp8VR2f2U0DV06nR++tqhdMd3uePrcNAMCmtcxTn09N8sHpSRoHJ3lfd3+0qj6R5OKqOjPJZ5O8Okm6+4aqujjJjUnuT3J2dz8w7et1Sd6V5JAkH5k+AACb2tKCWnd/Oslz1mj/YpKXrrPNuUnOXaN9R5Jn7+saAQBG5s0EAACDEtQAAAYlqAEADEpQAwAY1LIfeMsG27LtkoXWu/28U5ZcCQCwt4yoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAY1NKDWlUdVFVXV9WHp+UjqurSqrplmh4+t+45VXVrVd1cVS+ba39eVV03fffmqqpl1w0AsNH2x4ja65PcNLe8Lcll3X1Cksum5VTVM5OcluRZSU5O8taqOmja5vwkZyU5YfqcvB/qBgDYUEsNalV1bJJTkrxtrvnUJBdO8xcmedVc+0XdfV93fybJrUlOqqqjkxzW3Zd3dyd599w2AACb1l4Ftap6XFUduheb/JskP5/kwbm2p3b3XUkyTY+a2o9JcsfcejuntmOm+d3bAQA2tYcNalX1z6pqR1WdnuS/JLmlqn5uge1+JMnd3X3VgrWsdd1Z76F9rd88a6p1xz333LPgzwIAjOngBdY5O7Nrx/5Tki1JvpZkR5Jff5jtXpjklVX1iiRPSHJYVb0nyeer6ujuvms6rXn3tP7OJMfNbX9skjun9mPXaH+I7r4gyQVJsnXr1jXDHADAqljk1OdfdfeOJLd195e6+79lFtb2qLvP6e5ju3tLpqDX3T+ZZHuSM6bVzkjyoWl+e5LTqurxVXV8ZjcNXDmdHr23ql4w3e15+tw2AACb1iIjak+vqu1Jjp+mleT4R/Gb5yW5uKrOTPLZJK9Oku6+oaouTnJjkvuTnN3dD0zbvC7Ju5IckuQj0wcAYFNbJKidOk1/Y67t/96bH+nujyX52DT/xSQvXWe9c5Ocu0b7jiTP3pvfBABYdQ8b1Lr741X11CTPn5qu7O6797QNAACP3iJ3ff54kiszO0X540muqKofW3ZhAAAHukVOff5CkufvGkWrqiOT/L9JPrDMwgAADnSL3PX5mN1OdX5xwe0AAHgUFhlR+2hV/UGS90/Lr0ny+8srCQCAZLGbCX6uqn40yfdn9miOC7r7g0uvDADgAPewQa2q3tDdb0jye8svBwCAXRa51uyVS68CAICHWOQataOq6p/v3tjdb1pCPQAATBYJagcleVJm16cBALCfLBLUPtfdv7r0SgAA+CaLXKN26dKrAADgIRYZUXtLVX377o3d/dkl1AMAwGSRoHbJNH16ktsyu1atk3zPsooCAGCxB95+d5JU1dXd/dzllwQAQLJ37+zspVUBAMBDLPJmgh+dZp88N5/u9qYCAIAlWuQatX8wTT8+N9/xSikAgKVa5Bq11+6PQgAA+GYPe41aVX1nVV1WVddPy99TVb+4/NIAAA5si9xM8NtJzkny10nS3dcmOW2ZRQEAsFhQ+5buvnK3tvuXUQwAAN+wSFD7QlU9I9PjOarqx5LctdSqAABY6K7Ps5NckOS7quovknwmyU8utSr2uy3bLnn4lZLcft4pS64EANhlkbs+P53kh6rqiUke0933Lr8sAAAWeeDtL+22nCTp7l9dUk0AAGSxa9S2JTk5ydeTfHXuAwDAEi1yjdrTkvxPmb2V4M+SvGN6RAcAAEv0sCNq3f3l7v63Sf5RkkOSvG3pVQEAsNA1aj+c5PQkj0/yvszuAgUAYMkWuUbto0m+K8kTkrw2ye9V1falVgUAwELXqP3A0qsAAOAhFglq353kvd39X5ddDAAA37DIqc9vS/KJqrq4qk6uXQ9SAwBgqRa56/MXk5yQ5O1JfirJLVX1f03v/wQAYEkWGVFLd3eSz02f+5McnuQDVfWvl1gbAMABbZHHc/xMkjOSfCGzZ6j9XHf/dVU9JsktSX5+uSUCAByYFrmZ4ClJfrS7/3y+sbsfrKofWU5ZAAAscurz3+8e0qrqf0uS7r5pKVUBALBQUPtwVX1XklTV36mqjyc5cbllAQCwyKnPn0hyUVX9UWYPv/2Z7v7j5ZYFAMAij+e4KckrkvxgkvOENACA/eNhg1pVXZfZ+z4PS/Ifquraqrp26ZUBABzgFjn16c5OAIANsMipzz9P8uQk/2D6PHn3u0ABANj3Fjn1+fok701y1PR5T1X99LILAwA40C1y6vPMJN/X3V9Nkqp6Y5LLk/zWMgsDADjQLfIctUrywNzyA1MbAABLtMiI2juTXFFVH5yWX5XkHcsrCQCAZIGg1t1vmt5G8MLMRtJe291XL70yAIAD3CIjaunuq5JctWu5qs5K8m1JPtDdNy6pNgCAA9rDBrU1Hm5bSZ6e5PlJdi6jKAAAFhtROyizV0jtUkkuMZIGALBciwS1+3Z/wG1V3bekegAAmCwS1L6zqu5N8t+S/EWSD2f23k8AAJZokVdIPam7D03ytCSvTvLfk3xHVZ1eVd+x7AIBAA5UC931mSTd/UCS25L8WlVdn+SIpVUFAMDiQW1ed//HfV0IAADfbJFXSAEAsAEENQCAQS106rOqnpPkRdPin3T3p5ZXEgAAyQIjalX1+iTvTXLU9HlPVf30sgsDADjQLTKidmaS7+vuryZJVb0xyeVJfmuZhQEAHOgWuUatkjwwt/zA1AYAwBItMqL2ziRXVNUHp+VXJXn78koCACBZIKh195uq6mNJvj+zkbTXdvfVyy4MAOBAt+gDb2/r7k9W1QuSHFNV13X3/cssDADgQPewQa2q3pfkJVX14SR/O7OXs/9kktOWXBsAwAFtkRG1rUmenuSOJE/t7gend30CALBEi9z1+ZXu/lqSO7r7want60usCQCALDai9pyq+qsk3zJNK8kTllsWAAAPO6LW3Qd192HdffA0PbS7H/tw21XVE6rqyqr6VFXdUFW/MrUfUVWXVtUt0/TwuW3Oqapbq+rmqnrZXPvzquq66bs3V5XnuAEAm95evZS9qt6wF6vfl+QHu/s5SU5McvJ01+i2JJd19wlJLpuWU1XPzOwGhWclOTnJW6vqoGlf5yc5K8kJ0+fkvakbAGAV7VVQS/LKRVfsma9Mi4+dPp3k1CQXTu0XZvYA3UztF3X3fd39mSS3Jjmpqo5Oclh3X97dneTdc9sAAGxaexvU9uqUY1UdVFXXJLk7yaXdfUVmd47elSTT9Khp9WMyu7N0l51T2zHT/O7tAACb2t4Gteftzcrd/UB3n5jk2MxGx569h9XXCoG9h/aH7qDqrKraUVU77rnnnr0pFQBgOIs88Hb7bstJku7em9OgX55eQ3Vyks9X1dHdfdd0WvPuabWdSY6b2+zYJHdO7ceu0b7W71yQ5IIk2bp165phDgBgVSzyeI6/m+R/3tsdV9WRSf56CmmHJPmhJG9Msj3JGUnOm6YfmjbZnuR9VfWmJE/L7KaBK7v7gaq6d7oR4Yokpyf5rb2tBwBg1SwS1O7t7o8/gn0fneTC6c7NxyS5uLs/XFWXJ7m4qs5M8tkkr06S7r6hqi5OcmOS+5Oc3d0PTPt6XZJ3JTkkyUemDwDAprboA2+/nORrmZ1y/M9JfqW7v7Cnjbr72iTPXaP9i0leus425yY5d432HUn2dH0bAMCms9ADb5MckeQZSV6T5HP5xuM1AABYkoXu+uzuB7v7q919yzTq9dEl1wUAcMBb5NRnquqVSV48LX68u13MDwCwZIs8nuPXkpyU5L1T089U1d/v7nOWWhlD2rLtkoXWu/28U5ZcCQBsfouMqJ2S5MTufjBJqurCJFcnEdQAAJZo0TcTPHlu/luXUQgAAN9skRG1X0tydVX9UWavc3pxkn+51KoAAHj4oNbd759e//T8zILav+juzy27MACAA926pz6r6m+uBu/uu7p7e3d/KMlXq8pdnwAAS7ana9R+c3rN09+oqp9Icm2+8SJ1AACWZE+nPl+U5JKqOibJRUnemuTrSX6ou2/bH8UdaBZ99AUAcGBYd0Stu+9K8j9kFtiuTfK27n6FkAYAsH/s8fEc3X1vkpcnuTjJT1TVE/ZLVQAArH/qs6ruTdK7FpM8McmXquqBJN3dh+2H+gAADljrBrXuPnR/FgIAwDdb9M0EAADsZ4IaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABjUwRtdAJvTlm2XLLTe7eedsuRKAGB1GVEDABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxqaUGtqo6rqj+qqpuq6oaqev3UfkRVXVpVt0zTw+e2Oaeqbq2qm6vqZXPtz6uq66bv3lxVtay6AQBGscwRtfuT/O/d/XeTvCDJ2VX1zCTbklzW3SckuWxazvTdaUmeleTkJG+tqoOmfZ2f5KwkJ0yfk5dYNwDAEJYW1Lr7ru7+5DR/b5KbkhyT5NQkF06rXZjkVdP8qUku6u77uvszSW5NclJVHZ3ksO6+vLs7ybvntgEA2LT2yzVqVbUlyXOTXJHkqd19VzILc0mOmlY7Jskdc5vtnNqOmeZ3bwcA2NSWHtSq6klJfjfJP+3uv9rTqmu09R7a1/qts6pqR1XtuOeee/a+WACAgSw1qFXVYzMLae/t7t+bmj8/nc7MNL17at+Z5Li5zY9NcufUfuwa7Q/R3Rd099bu3nrkkUfuu44AAGyAZd71WUnenuSm7n7T3Ffbk5wxzZ+R5ENz7adV1eOr6vjMbhq4cjo9em9VvWDa5+lz2wAAbFoHL3HfL0zyj5NcV1XXTG3/Msl5SS6uqjOTfDbJq5Oku2+oqouT3JjZHaNnd/cD03avS/KuJIck+cj0AQDY1JYW1Lr7/8va15clyUvX2ebcJOeu0b4jybP3XXUAAOPzZgIAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoA7e6AI4sG3ZdslC691+3ilLrgQAxmNEDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxKUAMAGJSgBgAwKEENAGBQghoAwKAENQCAQR280QXAIrZsu2ThdW8/75QlVgIA+48RNQCAQQlqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABjUwRtdAOxrW7ZdstB6t593ypIrAYBHx4gaAMCgBDUAgEEJagAAgxLUAAAGJagBAAxqaUGtqt5RVXdX1fVzbUdU1aVVdcs0PXzuu3Oq6taqurmqXjbX/ryqum767s1VVcuqGQBgJMscUXtXkpN3a9uW5LLuPiHJZdNyquqZSU5L8qxpm7dW1UHTNucnOSvJCdNn930CAGxKSwtq3f3HSb60W/OpSS6c5i9M8qq59ou6+77u/kySW5OcVFVHJzmsuy/v7k7y7rltAAA2tf19jdpTu/uuJJmmR03txyS5Y269nVPbMdP87u0AAJveKDcTrHXdWe+hfe2dVJ1VVTuqasc999yzz4oDANgI+zuofX46nZlpevfUvjPJcXPrHZvkzqn92DXa19TdF3T31u7eeuSRR+7TwgEA9rf9HdS2Jzljmj8jyYfm2k+rqsdX1fGZ3TRw5XR69N6qesF0t+fpc9sAAGxqS3spe1W9P8lLkjylqnYm+eUk5yW5uKrOTPLZJK9Oku6+oaouTnJjkvuTnN3dD0y7el1md5AekuQj0wcAYNNbWlDr7n+0zlcvXWf9c5Ocu0b7jiTP3oelAQCshFFuJgAAYDeCGgDAoAQ1AIBBCWoAAIMS1AAABrW0uz5hdFu2XbLQerefd8qSKwGAtRlRAwAYlKAGADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1AAABiWoAQAMSlADABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAGdfBGFwCj27LtkoXWu/28U5ZcCQAHGiNqAACDEtQAAAYlqAEADEpQAwAYlKAGADAoQQ0AYFAezwH7iMd4ALCvGVEDABiUoAYAMChBDQBgUIIaAMCgBDUAgEEJagAAgxLUAAAG5TlqsJ953hoAizKiBgAwKEENAGBQghoAwKAENQCAQQlqAACDEtQAAAYlqAEADMpz1PaDRZ+bBQAwz4gaAMCgBDUAgEEJagAAg3KNGgzKO0EBMKIGADAoQQ0AYFCCGgDAoFyjBitub57T53o2gNViRA0AYFCCGgDAoAQ1AIBBuUYNDiCezQawWoyoAQAMyojao7A3d9sBAOwtI2oAAIMS1AAABiWoAQAMyjVqwEO4OxRgDEbUAAAGJagBAAxKUAMAGJRr1IBHzLVsAMtlRA0AYFBG1IClW4W3eBj1A0ZkRA0AYFCCGgDAoFbm1GdVnZzkN5MclORt3X3eBpcEHIDcQAHsTysR1KrqoCT/Nsn/mGRnkk9U1fbuvnFjKwM2i319Hd2+DnQbGRCFU9g4KxHUkpyU5Nbu/nSSVNVFSU5NIqgBK22jAuIybKZwCqNYlaB2TJI75pZ3Jvm+DaoFgEdhM4XTRe3rcHog2qh/hhv9PwKrEtRqjbZ+yEpVZyU5a1r8SlXdvNSqkqck+cKSf2N/2kz92Ux9STZXfzZTX5LN1Z/N1JdkoP7UGx/1Lobpyz6y1/3ZB/8MH5EFfndfHZvvWKtxVYLaziTHzS0fm+TO3Vfq7guSXLC/iqqqHd29dX/93rJtpv5spr4km6s/m6kvyebqz2bqS7K5+rOZ+pJsrv4suy+r8niOTyQ5oaqOr6rHJTktyfYNrgkAYKlWYkStu++vqn+S5A8yezzHO7r7hg0uCwBgqVYiqCVJd/9+kt/f6Dp2s99Os+4nm6k/m6kvyebqz2bqS7K5+rOZ+pJsrv5spr4km6s/S+1LdT/kmnwAAAawKteoAQAccAS1R6iqTq6qm6vq1qrattH1LKKqbq+q66rqmqraMbUdUVWXVtUt0/TwufXPmfp3c1W9bOMqT6rqHVV1d1VdP9e217VX1fOmfwa3VtWbq2qtR78s3Tr9eUNV/cV0fK6pqlfMfTdsf6rquKr6o6q6qapuqKrXT+0reXz20J+VOz5V9YSqurKqPjX15Vem9lU9Nuv1Z+WOzVwdB1XV1VX14Wl5JY/NOn1Z5eOyT/5e7pP+dLfPXn4yu6HhtiRPT/K4JJ9K8syNrmuBum9P8pTd2v51km3T/LYkb5zmnzn16/FJjp/6e9AG1v7iJN+b5PpHU3uSK5P8vcyezfeRJC8fqD9vSPKza6w7dH+SHJ3ke6f5Q5P8l6nmlTw+e+jPyh2f6XefNM0/NskVSV6wwsdmvf6s3LGZq/GfJ3lfkg9Pyyt5bNbpyyofl9uzD/5e7ov+GFF7ZP7mlVbd/fUku15ptYpOTXLhNH9hklfNtV/U3fd192eS3JpZvzdEd/9xki/t1rxXtVfV0UkO6+7Le/Zv0Lvnttmv1unPeobuT3ff1d2fnObvTXJTZm8TWcnjs4f+rGfY/vTMV6bFx06fzuoem/X6s56h+1NVxyY5Jcnbdqt55Y7NOn1Zz9B92YMNOTaC2iOz1iut9vQf8lF0kj+sqqtq9haHJHlqd9+VzP5AJTlqal+FPu5t7cdM87u3j+SfVNW1NTs1umtYfWX6U1Vbkjw3s5GOlT8+u/UnWcHjM52OuibJ3Uku7e6VPjbr9CdZwWOT5N8k+fkkD861reqxWasvyWoel2Tf/L3cJ/0R1B6ZhV5pNaAXdvf3Jnl5krOr6sV7WHdV+5isX/vofTo/yTOSnJjkriS/MbWvREbXXvEAAAXzSURBVH+q6klJfjfJP+3uv9rTqmu0rUJ/VvL4dPcD3X1iZm90Oamqnr2H1YfuS7Juf1bu2FTVjyS5u7uvWnSTNdpG78vKHZc5++Lv5T7pj6D2yCz0SqvRdPed0/TuJB/M7FTm56fh2UzTu6fVV6GPe1v7zml+9/YhdPfnpz9CDyb57XzjVPPw/amqx2YWat7b3b83Na/s8VmrP6t8fJKku7+c5GNJTs4KH5td5vuzosfmhUleWVW3Z3b5zA9W1Xuymsdmzb6s6HFJss/+Xu6T/ghqj8zKvdKqqp5YVYfumk/yw0muz6zuM6bVzkjyoWl+e5LTqurxVXV8khMyuyhyJHtV+zRUfW9VvWC68+b0uW023K7/AEz+YWbHJxm8P9Nvvz3JTd39prmvVvL4rNefVTw+VXVkVT15mj8kyQ8l+bOs7rFZsz+reGy6+5zuPra7t2T2N+Q/dfdPZgWPzXp9WcXjkuy7v5f7rD+9AXdTbIZPkldkdjfYbUl+YaPrWaDep2d2V8qnktywq+YkfyvJZUlumaZHzG3zC1P/bs4G3XkzV8v7Mxs6/+vM/i/lzEdSe5Kt079wtyV5S6aHPg/Sn/+Q5Lok107/4h+9Cv1J8v2ZDedfm+Sa6fOKVT0+e+jPyh2fJN+T5Oqp5uuT/NLUvqrHZr3+rNyx2a1fL8k37pRcyWOzTl9W8rhkH/693Bf98WYCAIBBOfUJADAoQQ0AYFCCGgDAoAQ1AIBBCWoAAIMS1IANU1XXV9WNVXVNVf1FVb1ho2sCGImgBmy0l/fslUD/z0YXAjAaQQ3YSI9Nct9aX1TVS6rqL6fRts9V1c9O7bdX1VOm+fdU1fXT/E9V1Vvmtn9LVf3UNP9LVfWJaQTvgukp4Wv95luq6rPTb36lqrZO7SdW1Z/W7OXSH6zp5dJV9bGq2lqzF4Vvr6rXVtUzquqTc/s8oaqumqv9/XPf/c702p1dLxv/9anOa6vqf5375/DhuW1+tqreUFUvmuq8sar++zR/zd70FxifoAZspEOT3LvOdwcl+fg02vbvdv+yqr47yZ5eMD7vLd39/O5+dpJDkvzIHn7zF6ff3DHX/u4k/6K7vyezJ63/8m7b/fskf9rd7+zu25L8ZVWdOH332iTvmlv3aVV1eFUdkeTb5trPTPKX3f38JM9P8r9Mr6NZU3f/yVTnK5Lc1t0nTst7019gcIIasCGq6qAkh3b3V9dZ5ZAkX9vDLv7PPDQwvWZuZOk1c+0/UFVXVNV1SX4wybPW2eeTknxptzq/NcmTu/vjU9OFSV48t8obkrwyyW/Mtb0tyWunPr4myfvmvnt/kp+YPvPtP5zk9Kn2KzJ7Xc0J03cvmuvXP1un9nmL9hcYnKAGbJSnZ/a+3PU8Lcmd63z395N8JbN38c37nbmRpd9Jkqp6QpK3Jvmx7v7uJL+d5Anr7Pf4zN69ujfuy2xE7Rfm2n43ycszG8m6qru/OPfd9syC3SuT/Me59kry07vq7+7ju/sPp+/+ZK5fe7yWby/7CwxOUAM2yo8nuXytL6aRqB9N8p/X2fYNSX5pwd/ZFVK+UFVPSvJj6/zmdyQ5OruFv+7+yyT/tapeNDX94yQfn1vl15L8qySvrKpnTdt8LckfJDk/yTt3+6mvJ/nTzPr+9bn2P0jyuqp67FTPd1bVExfs47yF+gushoM3ugDgwFNVr8ss3Hy2qr5/aj4yyUHThfinJbkls5GptVzR3bdV1ZaH+63u/nJV/XZm15bdnuQT66z6iSSPS3L1dO39307y60l+IMkZSf5dVX1Lkk9ndt3Z/G98varOTnJBVb2oux9M8t7MwuYfZjfd/ctJsuumiMnbkmxJ8snp4v97krzq4fr3KPoLrIDq7o2uATjATM9Lu72737VI+36q6WPd/ZLd2j7Q3Y9oRGq6S/Vbu/v/2Bf1AQcmI2oAM7+6RtsjerZbVX0wyTMyu5Af4BEzogbsd1V1cJLu7gcWaQc4UAlqAACDctcnAMCgBDUAgEEJagAAgxLUAAAGJagBAAzq/wdh4Y78P+zipgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xticks(np.arange(0, 10000, 500))\n",
    "\n",
    "plt.hist(data, bins=50)  # density=False would make counts\n",
    "plt.ylabel('Кол-во документов')\n",
    "plt.xlabel('Длина документа');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFlCAYAAAD76RNtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAV70lEQVR4nO3df5BdZ33f8fcnUpSEGAjBW0IkGWmCglEb7CaKgADFaeIikwTZKU2kkFJTQFUb0fQPGitNQ2npTHCYzFBqEY2Gekz6w8LFxCiJwJQmBhqgSGRk2TKVK2Rjb1TK2iYhBooR/vaPe4Svr+7unpXueqXH79fMztznOc+e+z1n7/3ouefcc5SqQpJ0/vuOpS5AkjQZBrokNcJAl6RGGOiS1AgDXZIaYaBLUiOWL9UTX3jhhbVmzZqlenpJOi999rOffaCqpsYtW7JAX7NmDQcPHlyqp5ek81KSL8y2zEMuktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjViyuy1KevJas/OPlrqEJXXv239mUdbrDF2SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEb0CvQkm5IcTXIsyc4xy5+e5A+S3J7kSJLXTb5USdJc5g30JMuAXcAVwHpga5L1I8N+Bbirqi4BLgN+J8mKCdcqSZpDnxn6RuBYVR2vqkeAvcDmkTEFPDVJgAuAh4CTE61UkjSnPoG+Erh/qD3d9Q27Dng+cAK4A/jVqnp0dEVJtiU5mOTgzMzMGZYsSRqnT6BnTF+NtF8BHAJ+ELgUuC7J0077pao9VbWhqjZMTU0tuFhJ0uz6BPo0sHqovYrBTHzY64AP1MAx4B7g4smUKEnqo0+gHwDWJVnbnejcAuwbGXMf8FMASZ4FPA84PslCJUlzm/f2uVV1MskO4FZgGXB9VR1Jsr1bvht4G3BDkjsYHKK5pqoeWKyivfXm2d960324OLcvlZZSr/uhV9V+YP9I3+6hxyeAvzPZ0iRJC+GVopLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDWi1/3QJT2e/0GI/0HIucgZuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIa0SvQk2xKcjTJsSQ7xyz/50kOdT93JvlWku+ffLmSpNnMG+hJlgG7gCuA9cDWJOuHx1TVO6rq0qq6FPh14GNV9dBiFCxJGq/PDH0jcKyqjlfVI8BeYPMc47cCN06iOElSf30CfSVw/1B7uus7TZKnAJuAm8++NEnSQvQJ9Izpq1nG/hzwp7MdbkmyLcnBJAdnZmb61ihJ6qFPoE8Dq4faq4ATs4zdwhyHW6pqT1VtqKoNU1NT/auUJM2rT6AfANYlWZtkBYPQ3jc6KMnTgZcDH5xsiZKkPub9P0Wr6mSSHcCtwDLg+qo6kmR7t3x3N/Qq4CNV9dVFq1aSNKte/0l0Ve0H9o/07R5p3wDcMKnCJEkL45WiktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmN6BXoSTYlOZrkWJKds4y5LMmhJEeSfGyyZUqS5rN8vgFJlgG7gMuBaeBAkn1VddfQmO8D3g1sqqr7kvy1xSpYkjRenxn6RuBYVR2vqkeAvcDmkTG/BHygqu4DqKovTbZMSdJ8+gT6SuD+ofZ01zfsh4FnJLktyWeTvHbcipJsS3IwycGZmZkzq1iSNFafQM+YvhppLwd+DPgZ4BXAbyb54dN+qWpPVW2oqg1TU1MLLlaSNLt5j6EzmJGvHmqvAk6MGfNAVX0V+GqSjwOXAHdPpEpJ0rz6zNAPAOuSrE2yAtgC7BsZ80HgZUmWJ3kK8ELgc5MtVZI0l3ln6FV1MskO4FZgGXB9VR1Jsr1bvruqPpfkw8Bh4FHgPVV152IWLkl6vD6HXKiq/cD+kb7dI+13AO+YXGmSpIXwSlFJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1olegJ9mU5GiSY0l2jll+WZK/THKo+3nL5EuVJM1l+XwDkiwDdgGXA9PAgST7ququkaGfqKqfXYQaJUk99JmhbwSOVdXxqnoE2AtsXtyyJEkL1SfQVwL3D7Wnu75RL05ye5IPJfnrE6lOktTbvIdcgIzpq5H2nwHPqaqHk7wSuAVYd9qKkm3ANoCLLrpogaVKkubSZ4Y+Daweaq8CTgwPqKqvVNXD3eP9wHcmuXB0RVW1p6o2VNWGqampsyhbkjSqT6AfANYlWZtkBbAF2Dc8IMkPJEn3eGO33gcnXawkaXbzHnKpqpNJdgC3AsuA66vqSJLt3fLdwKuBf5zkJPB1YEtVjR6WkSQtoj7H0E8dRtk/0rd76PF1wHWTLU2StBBeKSpJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IhegZ5kU5KjSY4l2TnHuB9P8q0kr55ciZKkPuYN9CTLgF3AFcB6YGuS9bOMuxa4ddJFSpLm12eGvhE4VlXHq+oRYC+wecy4NwE3A1+aYH2SpJ76BPpK4P6h9nTX921JVgJXAbvnWlGSbUkOJjk4MzOz0FolSXPoE+gZ01cj7XcC11TVt+ZaUVXtqaoNVbVhamqqb42SpB6W9xgzDaweaq8CToyM2QDsTQJwIfDKJCer6paJVClJmlefQD8ArEuyFvhzYAvwS8MDqmrtqcdJbgD+0DCXpCfWvIFeVSeT7GDw7ZVlwPVVdSTJ9m75nMfNJUlPjD4zdKpqP7B/pG9skFfV1WdfliRpobxSVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY3oFehJNiU5muRYkp1jlm9OcjjJoSQHk7x08qVKkuayfL4BSZYBu4DLgWngQJJ9VXXX0LD/DuyrqkryAuAm4OLFKFiSNF6fGfpG4FhVHa+qR4C9wObhAVX1cFVV1/xeoJAkPaH6BPpK4P6h9nTX9zhJrkryv4A/Av7hZMqTJPXVJ9Azpu+0GXhV/X5VXQxcCbxt7IqSbd0x9oMzMzMLq1SSNKc+gT4NrB5qrwJOzDa4qj4O/FCSC8cs21NVG6pqw9TU1IKLlSTNrk+gHwDWJVmbZAWwBdg3PCDJc5Oke/yjwArgwUkXK0ma3bzfcqmqk0l2ALcCy4Drq+pIku3d8t3A3wVem+SbwNeBXxw6SSpJegLMG+gAVbUf2D/St3vo8bXAtZMtTZK0EF4pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiF6BnmRTkqNJjiXZOWb5a5Ic7n4+meSSyZcqSZrLvIGeZBmwC7gCWA9sTbJ+ZNg9wMur6gXA24A9ky5UkjS3PjP0jcCxqjpeVY8Ae4HNwwOq6pNV9eWu+Wlg1WTLlCTNp0+grwTuH2pPd32zeT3woXELkmxLcjDJwZmZmf5VSpLm1SfQM6avxg5MfpJBoF8zbnlV7amqDVW1YWpqqn+VkqR5Le8xZhpYPdReBZwYHZTkBcB7gCuq6sHJlCdJ6qvPDP0AsC7J2iQrgC3AvuEBSS4CPgD8/aq6e/JlSpLmM+8MvapOJtkB3AosA66vqiNJtnfLdwNvAZ4JvDsJwMmq2rB4ZUuSRvU55EJV7Qf2j/TtHnr8BuANky1NkrQQXikqSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRvQK9CSbkhxNcizJzjHLL07yqSTfSPLmyZcpSZrP8vkGJFkG7AIuB6aBA0n2VdVdQ8MeAv4pcOWiVClJmlefGfpG4FhVHa+qR4C9wObhAVX1pao6AHxzEWqUJPXQJ9BXAvcPtae7vgVLsi3JwSQHZ2ZmzmQVkqRZ9An0jOmrM3myqtpTVRuqasPU1NSZrEKSNIs+gT4NrB5qrwJOLE45kqQz1SfQDwDrkqxNsgLYAuxb3LIkSQs177dcqupkkh3ArcAy4PqqOpJke7d8d5IfAA4CTwMeTfLPgPVV9ZVFrF2SNGTeQAeoqv3A/pG+3UOPv8jgUIwkaYl4pagkNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIa0SvQk2xKcjTJsSQ7xyxPknd1yw8n+dHJlypJmsu8gZ5kGbALuAJYD2xNsn5k2BXAuu5nG/C7E65TkjSPPjP0jcCxqjpeVY8Ae4HNI2M2A79XA58Gvi/JsydcqyRpDn0CfSVw/1B7uutb6BhJ0iJa3mNMxvTVGYwhyTYGh2QAHk5ytMfzn4suBB5YqifPtUv1zBPlPjw77r+zcz7vv+fMtqBPoE8Dq4faq4ATZzCGqtoD7OnxnOe0JAerasNS13E+cx+eHfff2Wl1//U55HIAWJdkbZIVwBZg38iYfcBru2+7vAj4y6r6PxOuVZI0h3ln6FV1MskO4FZgGXB9VR1Jsr1bvhvYD7wSOAZ8DXjd4pUsSRqnzyEXqmo/g9Ae7ts99LiAX5lsaee08/6w0TnAfXh23H9np8n9l0EWS5LOd176L0mNMNCBJFclqSQXd+01Sb6e5FCSu5L8XpLvTPKKru9Qkoe72yEc6pZf1q3j9UPr/Ztd35uXbuvOTpJnDm3zF5P8+VB7xQLXtbfbZ3cmeU+SXof8WpfkN5Ic6W6bcSjJC7vX29uT/O9uf30myRXd+HuT3NH93JXk3yb5rm7ZPUmeN7L+dyb5taXYtpE6TtvOrv+c29Yky5M8kOS3Rvpv617Dtyc5kOTSrv9/dtt0X5KZoffImm4bPjGynkNJ7jzbOk9TVU/6H+Am4BPAW7v2GuDO7vEy4I+B14z8zm3AhqH2ZcBh4CNDfdcCh4A3L/U2Tmg/vfVstoXBifMwmEj8V+CNS71NS/0DvBj4FPBdXftC4AeBtwPvHep/FvAL3eN7gQu7xxcA/wV4b9f+LeBfDa3/Oxh8rfg55+J2do+fsG0Frj71Pu/xWv1T4PN0h6a7/m+/7xl8+eO/jVn/dSN993Y5sLprP79r3znp/fykn6EnuQB4CfB6Bl/JfJyq+hbwGfpd+Xof8N1JnpUkwCbgQxMs95yS5Ne6GdWdSd7U9T23m4X9x25WdVOS74HByfUaeJTBPl2VZFmSLyR5Wvf7SXI8yYXdfvxAkoPdrO1F3ZinJnlvt/7DSa5cqn0wAc8GHqiqbwBU1QPAXwBvBN401P9/q+qm0V+uqoeB7cCVSb4fuJHHv47/FnBvVX1hcTdjXqdtZ1WdSPIUzs1t3Qr8Owbv6RfNMuZT9L8i/ibgF4fWfeNZVTeLJ32gA1cCH66qu4GHMnKnyCTfDbwQ+HDP9b0f+HvATwB/BnxjgrWeM5JsBF7D4F4/Lwb+SZIXdIvXA7uq6keA/wf8o5HfXdH97oe7fzD/kMfuD/QTwN1dsL0L+O0aXADyC8B7ujFvBWa69V8CfGxRNvKJ8RFgdZK7k7w7ycuB5wL3VdVX+qygG3cPsK6qDgOPJrmkW7yFRQqPBRq3nXAObms3AfkpBq/LGxkE8DibgFt6rvb9wM93j38O+IOzqXE2Bvrgj7W3e7yXx/54P5TkEPAggxfc4Z7ru4lBoC/av8LniJcBN1fV16rqrxi8sF/aLbunBjdpA/hPQ/2n7AY+WlWf6trv47HZy5auDfDTwO7u73AL8IzuzfbTDO4ASjfj//JkN+2J0806f4zBLTFmGGz7ZWewquHbb9wIbOnOUWxmcHhrSY3bziRXn+HqFrStGToPBPwbYPvQMe4fGbP+nwX+pKq+BtwMXJXBXWdP+c9JpoFrgH/fs+aHgC8n2QJ8jsH1OhP3pD4pleSZwN8G/kaSYnC8vIB3A5+vqkszuGvkbUleVVWjV8iepqq+mOSbwOXArzKYcbZo3P17Thn9Luy320neBjwdeMPQ8k8AN3R/j1cBvzn0HBtrcJdPhtaRMc9x3uo+pdzG4HV2B4NPNBcleWr3j+WckjyVwXmfu7uuGxnMiD8GHK6qLy1G3Qs1Zjv/AYMJ0KJua1U9CJw6eXk1sKaq3jrH02wFXpLk3q79TOAngY927dcAtzM49r+Lx2be83lfN/7qnuMX7Mk+Q381g9v+Pqeq1lTVagYf51adGlCDWxjsBH59Aet9C3BN9wJu1ccZzFy+pzsPsZlBMAOsTfLj3eOtwP8AyODq4ssYnGB+9NSKanCm6IPAO4Hbq+ovukUfZeiCtVPfKGDwBt7R9SXJMya/eU+MJM9Lsm6o61LgKPAfgHd1h6dI8uwkvzzm9y9gMAG55dQnlar6PINPlm/nHPmUOMt2fqGbBZ8z29qdy3kpcFGXCWsYvAYfd9ilqr4J/EvgRUme33P1vw/8NoOr7hfFkz3QtzLYycNuBv7FSN8twFOSvKzPSqvqk1XV99jaeamqPsPgDXQA+DTwu1V1R7f4CPDGJIeB7wX2dB9Zr2NwcuzT3cfd3xha5fuAX+axwy0weCO9pDvxeReDk2cA/xp4Vve1r0MMDv+cry4A3pvBV/IOMzj/8FYGYTED3NVt5y1d+5Q/6fo/w+DE3ePOUzD421zM6a/vpTLbdsK5ta0/D/zxqRO0nQ8Cr0r3dclTqurrwO8Avb6WXFV/VVXXjn7inCSvFNVEJXku8P6qunTewZIm6sk+Q5ekZjhDl6RGOEOXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5Jjfj/9KtrS5C8ZrMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = [\"ARTM\", \"Top2vec\", \"SCDV\", \"SCDV + ARTM\"]\n",
    "counts = [0.79, 0.79, 0.745, 0.83]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(groups, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = [\"math + cs\", \"гум.\", \"др.\"]\n",
    "counts = [0.92, 0.67, 0.86]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.yticks(np.arange(0, 0.9, 0.1))\n",
    "plt.bar(groups, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x275a8f2ec70>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_par = [\"ARTM\", \"Top2vec\", \"SCDV\"]\n",
    "g1 = [0.79, 0.79, 0.745]\n",
    "g2 = [0.765, 0.783, 0.725]\n",
    "width = 0.3\n",
    "x = np.arange(len(cat_par))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yticks(np.arange(0, 1, 0.1))\n",
    "rects1 = ax.bar(x - width/2, g1, width, label='С шумом')\n",
    "rects2 = ax.bar(x + width/2, g2, width, label='Без шума')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cat_par)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectores = list()\n",
    "length = len(soft_clustersKD_ARTM_new['регрессия'])\n",
    "for elem in test_data[110*2:110*(2+1)]:\n",
    "    sum_ = np.array([0]*length)\n",
    "    counter = 0\n",
    "    for word in elem.split():\n",
    "        try:\n",
    "            sum_ = sum_ + np.array(soft_clustersKD_ARTM_new[word])\n",
    "            counter = counter + 1\n",
    "        except:\n",
    "            pass\n",
    "    test_vectores.append(sum_/counter)\n",
    "\n",
    "for ind, elem in enumerate(test_vectores):\n",
    "    test_vectores[ind] = elem/sum(elem)\n",
    "results = list()\n",
    "for i in [i*11 for i in range(10)]:\n",
    "    results.append(dist_top10(test_vectores[i], test_vectores))\n",
    "    \n",
    "leest = list()\n",
    "for i in range(10):\n",
    "    leest.append(prec(list(map(lambda x: x[0], results[i])), 10, i*11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.9, 1.0, 0.9, 0.8, 1.0, 1.0, 1.0, 0.9]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.10953356570675676),\n",
       " (5, 0.11873308595437826),\n",
       " (7, 0.15077819595760367),\n",
       " (2, 0.2852403098688534),\n",
       " (6, 0.37847128632793225),\n",
       " (4, 0.6020588696697629),\n",
       " (9, 0.6144910263595542),\n",
       " (8, 0.6615262847841696),\n",
       " (1, 0.6913443467696925),\n",
       " (50, 0.7089510997777836)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рито́рика ( др.-греч. ἡ ῥητορικὴ τέχνη «ораторское искусство» ← ῥήτωρ « оратор ») — филологическая дисциплина, изучающая искусство речи , правила построения художественной речи, ораторское искусство, мировоззрение и красноречие [1] [2] . Первоначальное значение слова риторика — наука об ораторском искусстве — впоследствии расширилось до теории прозы, аргументации . Европейская риторика началась в Древней Греции, в школах софистов , практиковавших обучение красноречию и собиравших стилистические и грамматические правила. Риторика развивалась под влиянием Аристотеля [3] , Цицерона и Квинтилиана . Расцвет христианского красноречия относится к IV−V векам. Западное красноречие было особенно сильным в Италии ( Бембо и Кастильоне ; XVI век), где, благодаря противостоянию латинского (научного) и итальянского (народного) языков получило развитие учение о трёх стилях . В России до Петра I существовало исключительно духовное красноречие [4] , которое преподавали в юго-западных духовных школах с XVII века на латыни и которое изучается гомилетикой . Первые русские научные труды по риторике были изданы М. Ломоносовым («Риторика», 1748; «Рассуждение о пользе книг церковных», 1757). [5] [6] В XX веке слово «риторика» стало пониматься в двух значениях [7] : По словам Диогена Лаэртского , Аристотель приписывал изобретение риторики пифагорейцу Эмпедоклу , сочинение которого неизвестно нам даже по названию. Из текстов самого Аристотеля и из других источников известно, что первый трактат по риторике принадлежал ученику Эмпедокла Кораксу , любимцу сиракузского тирана Гиерона I , политическому оратору и адвокату (судебному оратору). Он сформулировал не лишённое интереса определение красноречия: «красноречие есть работница убеждения ( др.-греч. πειθοῦς δημιουργός )». Он первый делает попытку установить чёткое деление ораторской речи на части: вступление ( προοίμιον ), предложение ( κατάστασις ), изложение ( διήγησις ), доказательство или борьба, падение и заключение. Он же высказал положение, что главная цель оратора — не раскрытие истины, но чёткость и убедительность при помощи вероятного ( εἰκός ), для чего чрезвычайно полезны всякие софизмы . Труд Коракса до нас не дошёл, но древние писатели сообщают нам примеры его софизмов, из которых особенной славой пользовался так называемый крокодилит . Ученик Коракса, Тисий , развивал ту же систему софистических доказательств и главным средством преподавания риторики считал заучивание образцовых речей судебных ораторов . Традиционно учеником Эмпедокла считается и Горгий , который, по словам Платона , «открыл, что вероятное важнее истинного, и умел в своих речах малое представить великим, а великое малым, выдать старое за новое и новое признать старым, об одном и том же предмете высказывать противоречивые мнения» [8] . Метод преподавания у Горгия тоже состоял в изучении образцов; каждый его ученик должен был знать отрывки из произведений лучших ораторов, чтобы уметь дать ответ на чаще всего выставляемые возражения. Горгию принадлежал любопытный трактат «О приличном случаю» ( др.-греч. περὶ τοῦ καιροῦ ), где говорилось о зависимости речи от предмета, от субъективных свойств оратора и аудитории , и давалось наставление, как при помощи насмешки уничтожать серьёзные доводы и, наоборот, на насмешку отвечать с достоинством. Красивое говорение (красивую речь, др.-греч. εὐέπεια ) Горгий противопоставлял утверждению истины (правильной речи, ὀρθοέπεια ). Он приложил много сил к созданию правил относительно фигур : метафор , аллитерации , параллелизма частей фразы. Из школы Горгия вышли многие знаменитые риторы: Ликимний Хиосский [de] , Фрасимах , Эвен Паросский , Феодор Византийский [en] . К тому же стилистическому направлению риторики принадлежали софисты Протагор и Продик , а также знаменитый оратор Исократ , разработавший учение о периоде. Направление этой школы можно назвать практическим, хотя оно и подготовило богатый психологический материал для выработки общих теоретических положений об ораторском искусстве и этим облегчило задачу Аристотелю, который даёт в своей знаменитой «Риторике» научное обоснование прежним догматическим правилам, пользуясь чисто эмпирическими приёмами. Аристотель в своей «Риторике» значительно расширил область риторики, сравнительно с точкой зрения, распространенной на неё в то время. Так как дар речи, по его мнению, имеет характер всеобщности и находит применение при самых разнообразных случаях и так как действие при подаче совета, при всякого рода разъяснениях и убеждениях, приводимых для одного лица или для целых собраний (с которыми имеет дело оратор), по существу одинаково, то риторика так же мало, как и диалектика , имеет дело с какой-нибудь одной определённой областью: она обнимает все сферы человеческой жизни. Риторикой, понимаемой в таком смысле, пользуются все на каждом шагу: она одинаково необходима как в делах, касающихся житейских нужд отдельного человека, так и в делах государственной важности: раз человек начинает склонять к чему-нибудь другого человека или отговаривать его от чего-нибудь, он необходимо прибегает к помощи риторики, сознательно или бессознательно. Понимая риторику таким образом, Аристотель определяет её как способность находить возможные способы убеждения относительно каждого данного предмета [9] . Из определения риторики становится ясна цель, которую преследовал Аристотель в своём трактате: он хотел, на основании наблюдения, дать общие формы ораторского искусства , указать, чем должен руководиться оратор или вообще всякий, желающий убедить кого-либо в чём-либо. Сообразуясь с этим, он разделил свой трактат на три части. Первая часть посвящена анализу тех принципов, на основании которых оратор (то есть всякий говорящий о чём-нибудь) может побуждать к чему-нибудь своих слушателей или отклонять их от чего-нибудь, может хвалить или порицать что-нибудь. Вторая часть говорит о тех личных свойствах и особенностях оратора, с помощью которых он может внушить доверие своим слушателям и таким образом вернее достигнуть своей цели, то есть уговорить или отговорить их. Третья часть касается специальной (технической) стороны риторики: Аристотель говорит здесь о тех способах выражения, которыми должно пользоваться в речи (о стиле ), и о построении ораторской речи . Множество тонких психологических замечаний по вопросу о взаимодействии оратора и аудитории (например, о значении юмора , пафоса , о влиянии на молодых людей и на стариков) и анализ силы используемых в речи доказательств придают работе Аристотеля универсальное значение. Труд Аристотеля оказался менее востребован, чем практические руководства ( др.-греч. τέχναι , их авторов называли «технографами») для ораторов. Первое такое руководство принадлежит Анаксимену Лампсакскому (около 340 г. до н. э.). После македонского завоевания исчезло политическое красноречие демосфеновского типа, пришло в упадок судебное красноречие, зато риторика процветала в школах, где обычным упражнением стало сочинение речей для вымышленных судебных дел. В Древний Рим риторика проникла в I веке до н. э. . Древнейшей латинской риторикой считается анонимная « Риторика для Геренния » (80-е гг. до н. э.). Труды о риторике Цицерона — одна из самых значимых частей его наследия (7 трактактов, датированных между 85 и 44 гг. до н. э.). Трактат Дионисия Галикарнасского (жившего в Риме) «О соединении слов» (2-я половина I в. до н. э.) интересен рассмотрением риторики литературной в связи с риторикой музыкальной (в частности, автор проводит чёткое разграничение между ораторской речью и вокальной музыкой). Все эти труды основаны на греческих (эллинистических) образцах. Наиболее полное выражение римская риторика получила в масштабной работе Квинтилиана «Наставления оратору» в 12 книгах (около 95 года н. э.), автор которой видит в ораторе идеал человека. Красноречие для Квинтилиана стоит выше, чем астрономия, математика и другие науки. Эллинистическая риторика (в Риме сложилась ко времени Цицерона) делилась на 5 частей: В состав учения о словесном выражении входило и учение о трёх стилях : в зависимости от использования стилистических средств — о простом ( низком ), среднем и высоком стиле речи. Эта теория сохраняла своё значение в Средние века и в эпоху Возрождения. После исчезновения демократии античная риторика ориентировалась главным образом на два типа речей: на судебные и парадные речи. Соответственно двум этим целям (утилитарной и эстетической) формируются два направления в теории стиля: аттицизм ( аттикизм , аттическое направление), заботившийся преимущественно о точности выражения, и азианизм (азианство, азиатское направление), ставивший целью занимательность изложения и выработавший особый высокий стиль, основанный на контрастах , изобилующий сравнениями и метафорами . В римской риторике продолжался спор об азианизме и аттицизме. Первым последователем азианизма был Гортензий , а впоследствии к нему примкнул Цицерон, высказывающийся, впрочем, в некоторых сочинениях и в пользу аттицизма. Наиболее изящным представителем аттицизма в римской литературе можно считать Юлия Цезаря . Разработка материала в римской риторике подчинялась особой конечной цели, убеждению, в котором различались три аспекта — docere («учить», «сообщать»), movere («побуждать», «возбуждать страсти»), delectare («развлекать», «доставлять наслаждение»). Каждый из них был неразрывно связан с остальными, но, смотря по обстоятельствам, мог занимать господствующее положение. Было унаследовано и учение о разработке пяти этапов речи. С падением республики красноречие как таковое приходит в упадок (описанный Тацитом в «Диалоге об ораторах»), зато риторические приёмы проникают в поэзию. Пионером здесь выступил Овидий , добавляющий с помощью антитез остроумия своим стихам. Напротив, Сенека и Лукан стремятся достичь трагического эффекта нагнетанием пафоса. В эпоху борьбы христианства с античным язычеством была создана наука о христианском ораторском искусстве, достигшем блистательного развития в IV и V веках н. э. . Выдающийся представитель этого ораторского искусства — Иоанн Златоуст . В теоретическом смысле средневековая риторика почти ничего не прибавляет к античным разработкам, держится правил Аристотеля и поздних теоретиков (на Западе — Цицерона ) и лишь перерабатывает их в расчёте преимущественно на сочинение писем и проповедей . Повсеместно происходит ужесточение требований к соблюдению этих правил. Уже к IV веку сфера действия риторических норм совпала с самим понятием литературы : в латинской литературе средних веков риторика заменяет поэтику , прочно забытую средневековой традицией. Теоретики задавались вопросом: ограничен ли материал, о котором может идти речь в литературном тексте? На сей счет высказывались самые разные мнения. В целом победила максималистская тенденция: в компетенцию риторики по крайней мере до XIII века входил любой материал. Следуя этому искусству, автор, прежде чем создавать произведение, должен был составить себе ясное и рациональное представление ( intellectio ) о предполагаемом материале. В средневековой риторике сохранялось учение об убеждении как об основной задаче и о трёх задачах («учить, побуждать, развлекать» лат. docere, movere, delectare ). Создание произведения, в свою очередь, подразделялось на три части или ступени (три главных элемента из пяти в античном списке). Перенимая идеи античных наставников, создатели риторик XI—XIII веков сосредоточивают основное внимание на амплификации и на учении об украшенном слоге, в котором они видят самую суть письменного слова: их деятельность сводится главным образом к перечислению и упорядочению тех способов выражения, какие в своем первозданном виде уже существуют в обыденном языке; они описывают их в функциональных понятиях, как код типов слога с высокой степенью вероятности. В 1920—1950 гг. многие медиевисты, в том числе и Э. Р. Курциус , полагали, что риторическая модель применима ко всем областям словесности, и делали из этой гипотезы далеко идущие выводы. В Византии приёмы риторики ближе всего подходят к азианизму , и в таком виде эта наука передаётся и Древней Руси , где художественные образцы её влияния мы можем видеть в произведениях митрополита Иллариона и Кирилла Туровского . В эпоху Возрождения и классицизма риторика перерабатывалась в теорию, применимую ко всякой художественной прозе . Литературные герои — яркие представители ораторского искусства. Из реальных персонажей эпохи Возрождения ораторов мало, настоящую яркую речь можно было услышать только в театре. Риторика, как вид искусства, в средние века не развивалась. Жёстко-нормативный характер утверждается за европейской риторикой особенно в Италии , где, благодаря встрече латинского языка учёных и народного итальянского языка , лучше всего находит себе применение теория трёх стилей. В истории итальянской риторики занимают видное место Бембо и Кастильоне , как стилисты . Законодательное направление особенно ярко выражается в деятельности академии делла Круска , задача которой состоит в сохранении чистоты языка. В произведениях, например, Спероне Сперони заметно подражание приёмам Горгия в антитезах , ритмическом строении речи, подборе созвучий, а у флорентийца Даванцати замечается возрождение аттицизма . Только в эпоху Возрождения заново становится известен Квинтилиан , чьё творчество было утрачено в Средние века. Из Италии это направление передаётся Франции и другим европейским странам. Создаётся новый классицизм в риторике, находящий самое лучшее выражение в «Рассуждении о красноречии» Фенелона . Всякая речь , по теории Фенелона, должна или доказывать (обыкновенный стиль), или живописать (средний), или увлекать (высокий). Согласно с Цицероном , ораторское слово должно приближаться к поэтическому; не нужно, однако, нагромождать искусственные украшения. Надо во всём стараться подражать древним; главное — ясность и соответствие речи чувству и мысли. Интересные данные для характеристики французской риторики можно найти и в истории Французской академии и других учреждений, охранявших традиционные правила. Аналогично и развитие риторики в Англии и Германии в течение всего XVIII века . В таком виде риторика оставалась частью гуманитарного образования во всех европейских странах вплоть до XIX века . Развитие политического и других видов красноречия и романтической литературы приводит к упразднению условных правил ораторского искусства. Традиционно наиболее значимая часть — учение о словесном выражении — растворилась в стилистике как части теории литературы , а остальные разделы потеряли практическое значение. Именно тогда слово «риторика» приобрело одиозный оттенок напыщенного пустословия. Слово риторика применялось для вновь создаваемых дисциплин — теории прозы (преимущественно художественной прозы — XIX век, немецкая филология), стилистики (XX век, французская филология), теории аргументации (XX век, бельгийский философ Х. Перельман ) В России, в допетровский период развития литературы, риторика могла иметь применение лишь в области духовного красноречия, и число её памятников совершенно ничтожно: мы имеем некоторые стилистические замечания в Изборнике Святослава (1073 и 1076), трактат XVI века « Речь тонкословия греческого » [10] и «Науку о сложении проповедей» Иоанникия Галятовского. Систематическое преподавание риторики начинается в юго-западных духовных школах с XVII века , причём учебники — всегда латинские, так что оригинальной обработки в них искать не приходится. Первым серьёзным русским трудом является Краткое руководство к красноречию Ломоносова («Риторика» Ломоносова, 1748 ), составленная на основании классических авторов и западноевропейских руководств и дающая в подтверждение общих положений ряд примеров на русском языке — примеров, извлеченных частью из сочинений новых европейских писателей. Ломоносов же, в своём « Рассуждении о пользе книг церковных », применяет к русскому языку западную теорию трёх стилей. Ввиду того, что область красноречия в России ограничивалась почти исключительно церковной проповедью, риторика здесь почти всегда совпадала с гомилетикой . По светской риторике в России было создано очень мало работ, да и те не отличались самостоятельностью, как, например, руководства Н. Ф. Кошанского . Научная разработка риторики в том смысле, как она понимается на Западе, в России не начиналась по крайней мере до XX века . Концепция школьной риторики как учебного предмета реализована в учебных пособиях для 1-11 классов Т. А. Ладыженской [11] . Основная цель школьной риторики — обучение успешному общению . В содержание школьной риторики включаются: Также основы риторики изучают в вузах, в основном на философских, педагогических и других гуманитарных факультетах. Для тех же, кто нуждается в освоении техники публичных выступлений в более старшем возрасте, рынок образовательных услуг России и Украины предлагает большое количество тренинговых программ и курсов по риторике. Обучающие курсы по изучению приемов риторики могут быть государственными: Московский педагогический государственный университет (Москва); государственный университет им. Н. И. Лобачевского (Нижний Новгород); институт подготовки кадров-курсы публичных выступлений (Киев), а также коммерческими (университет риторики и ораторского мастерства, школа красноречия, школа жесткой риторики и т. д. Посещая подобного рода курсы и тренинги по риторике, возможно освоить основные правила и техники публичных выступлений, избавиться от страха перед аудиторией, качественно улучшить дикцию и произношение, отработать основные способы защиты от диверсий и приемов «черной» риторики. Также, на курсах и тренингах обучают аргументировать, убеждать и отстаивать свою позицию, контролировать своё невербальное сообщение, держать смысловые паузы, зажигать и вдохновлять слушателей и т. д. Для известного в Античности ритора Горгия и его учеников главным было выиграть дело любым способом. Поэтому Платон устами Сократа , для которого было важным не грешить против справедливости и добра, противопоставляет риторике этику , ставя этику превыше риторики. В диалоге Платона « Горгий » Сократ остерегается, что он может пострадать от риторов — обвинителей на суде, если обвинителями Сократа окажутся люди непорядочные, «негодяи» [12] [13] . Оценить действия ритора с позиций нравственности и морали позволяет понятие о риторической этике — поведении ритора, основанное на правовых, нравственных, моральных и технических нормах речи [ уточнить ( обс. ) ] [14] . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts_1[11*9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Литература ( лат. lit(t)eratura , — написанное , от lit(t)era — буква) — в широком смысле слова совокупность любых письменных текстов . Чаще всего под литературой понимают художественную литературу , то есть литературу как вид искусства . Однако это понимание, сложившееся в эпоху романтизма , не следует прямо применять к культуре отдалённых от сегодняшнего дня эпох. Древние научные трактаты и религиозно - мифологические сочинения — такие, например, как « Теогония » Гесиода или « О природе вещей » Лукреция — с точки зрения современников не противопоставлялись, например, эпическим поэмам (« Илиаде » Гомера или « Энеиде » Вергилия ) как нехудожественная литература художественной. В России ещё в 1820-е годы критики сходились во мнении, что лучшие образцы русской прозы — « История Государства Российского » Карамзина и « Опыт теории налогов » Николая Тургенева [1] . Отделяя художественную литературу других периодов от литературы религиозной, философской, научной, публицистической, мы проецируем наши современные представления в прошлое. Тем не менее у литературы есть ряд универсальных свойств, неизменных во всех национальных культурах и на всем протяжении человеческой истории, хотя каждое из таких свойств связано с определёнными проблемами и оговорками. Всем трём названным критериям не вполне удовлетворяют некоторые древние тексты, традиционно понимаемые как литературные, — например, « Илиада » и « Одиссея »: вполне вероятно [2] , что Гомер как единый автор этих двух поэм никогда не существовал, а тексты этих двух поэм сложились из древнегреческого фольклора, исполнявшегося сказителями в виде песен. Однако письменная фиксация этих текстов в их окончательном варианте состоялась настолько давно, что такой традиционный подход можно считать оправданным. Следует добавить ещё один критерий, относящийся уже не к структуре литературных текстов, а к их функции. Виды литературы могут выделяться как по содержанию текстов, так и по их предназначению, и полностью соблюсти принцип единства основания при классификации литературы затруднительно. К тому же такая классификация способна вводить в заблуждение, объединяя непохожие и абсолютно различные явления. Зачастую типологически различные тексты одной и той же эпохи гораздо ближе друг к другу, чем типологически одинаковые тексты разных эпох и культур: у лежащих в основе европейской философской литературы «Диалогов» Платона куда больше общего с другими памятниками древнегреческой словесности (скажем, с драмами Эсхила ), чем с трудами таких философов Нового времени, как Гегель или Рассел . Судьба некоторых текстов складывается таким образом, что во время своего создания они тяготеют к одному виду литературы, а впоследствии движутся в сторону другого: так, например, « Приключения Робинзона Крузо », написанные Даниэлем Дефо , прочитываются сегодня скорее как произведение детской литературы , а между тем писались они даже не просто как произведение художественной литературы для взрослых, а как памфлет с существенной ролью публицистического начала. Поэтому общий список основных видов литературы может носить только приблизительно-ориентировочный характер, а конкретная структура литературного пространства может быть установлена только применительно к данной культуре и данному периоду времени. Для прикладных целей, однако, эти сложности не имеют принципиального значения, так что практическим нуждам книжной торговли и библиотек удовлетворяют довольно разветвлённые, хотя и поверхностные по подходу системы библиотечно-библиографической классификации . Художественная литература — вид искусства , использующий в качестве единственного материала слова и конструкции естественного (письменного человеческого) языка . Специфика художественной литературы выявляется в сопоставлении, с одной стороны, с видами искусства, использующими иной материал вместо словесно-языкового ( музыка , изобразительное искусство ) или наряду с ним ( театр , кино , песня ), с другой стороны — с иными типами словесного текста : философским , публицистическим , научным и др. Кроме того, художественная литература, как и другие виды искусства, объединяет авторские (включая и анонимные) произведения в отличие от принципиально не имеющих автора произведений фольклора . Документальная проза — вид литературы, для которого характерно построение сюжетной линии исключительно на реальных событиях, с редкими вкраплениями художественного вымысла. Документальная проза включает биографии чем-либо выдающихся людей, истории каких-либо событий, страноведческие описания, расследования громких преступлений. Мемуары — записки современников, повествующие о событиях, в которых автор мемуаров принимал участие или которые известны ему от очевидцев. Важная особенность мемуаров заключается в установке на «документальный» характер текста, претендующего на достоверность воссоздаваемого прошлого. Научная литература — совокупность письменных трудов, которые созданы в результате исследований, теоретических обобщений, сделанных в рамках научного метода. Научная литература предназначена для информирования учёных и специалистов о последних достижениях науки, а также для закрепления приоритета на научные открытия. Как правило, научная работа не считается завершённой, если она не была опубликована. Первые научные произведения создавались в различных жанрах: в виде трактатов, рассуждений, поучений, диалогов, путешествий, жизнеописаний и даже в стихотворных формах. В настоящее время формы научной литературы стандартизованы и состоят из монографий, обзоров, статей, докладов (в том числе их тезисов), авторефератов, рефератов и рецензий. В настоящее время во многих странах действует механизм аттестации научной литературы, поддерживаемый правительством или общественными научными организациями. В России, например, такую аттестацию проводит ВАК (Высшая аттестационная комиссия). В числе основных требований к изданию научной литературы — обязательное её рецензирование. В рамках этого процесса издательство или редакция научного журнала перед публикацией новой научной работы направляет её нескольким (обычно двум) рецензентам, считающимися специалистами в данной области. Процесс рецензирования призван исключить публикации в рамках научной литературы тех материалов, которые содержат грубые методологические ошибки или прямые фальсификации. С начала XX века наблюдается регулярное экспоненциальное увеличение объёма публикуемой научной литературы. В связи с этим, одним из самых главных носителей научной литературы в настоящее время являются периодические издания, главным образом, рецензируемые научные журналы. С конца XX века наблюдается тенденция по переходу этих журналов с бумажных носителей на электронные, в частности в Интернет. Научно-популярная литература — литературные произведения о науке, научных достижениях и об учёных, предназначенные для широкого круга читателей. Научно-популярная литература направлена как на специалистов из других областей знания, так и на малоподготовленных читателей, включая детей и подростков. В отличие от научной литературы, произведения научно-популярной литературы не рецензируются и не аттестуются. Научно-популярная литература включает произведения об основах и отдельных проблемах фундаментальных и прикладных наук, биографии деятелей науки, описание путешествий и т. д., написанные в различных жанрах. Лучшие популярные сочинения пропагандируют достижения передовой науки в форме, наиболее доступной читателям, которым они предназначены. В поэтической форме были написаны первое в Европе популярное произведение о науке — «О природе вещей» Лукреция Кара и «Письмо о пользе стекла» М. В. Ломоносова. Из бесед возникли «История свечи» М. Фарадея и «Жизнь растения» К. А. Тимирязева. Известны популярные сочинения, написанные в форме календаря природы, этюдов, очерков, «интеллектуальных» приключений и т. п. Литература вспомогательного содержания, используемая для получения наиболее общей, не вызывающей сомнений информации по тому или иному вопросу. Основные виды справочной литературы: В идеале справочные издания должны содержать только считающиеся объективно установленными факты и адекватно отражать существующий в данный момент уровень человеческих знаний. Однако на практике невозможно полностью отделить факты от интерпретаций и неявных, подразумеваемых допущений, поэтому та или иная доля тенденциозности в любом справочном издании присутствует. В некоторых случаях эта доля довольно велика и привносится в справочное издание целенаправленно: таковы, в частности, большинство справочных изданий советской эпохи, особенно в том, что касается гуманитарного знания, — даже короткие словарные статьи оказываются в них идеологически окрашены. Касается это и отбора материала: так, в литературных энциклопедиях, выпущенных в СССР, находилось место для сугубо второстепенных писателей социалистической и коммунистической ориентации, но отсутствовали весьма значительные авторы, известные своим негативным отношением к советскому строю. Даже спустя короткое время пользоваться такими изданиями как справочными становится невозможно: слишком много усилий приходится затрачивать на то, чтобы отделить факты от интерпретаций; однако именно эта идеологическая окраска делает справочные издания особенно интересными как историческое свидетельство, памятник своей эпохи. Учебная литература, делящаяся в основном на собственно учебники и сборники задач (упражнений), имеет немало общего со справочной: как и справочная литература, учебная имеет дело с той частью знаний по тому или иному вопросу, которая считается более или менее общепризнанной. Однако назначение учебной литературы иное: изложить эту часть знаний системно и последовательно с тем, чтобы адресат текста составил о ней достаточно полное и отчётливое представление и овладел рядом востребованных в этой части знаний навыков, будь то умение решать уравнения или правильно расставлять знаки препинания . Эта прагматическая задача определяет особенности строения учебных текстов: повторы, подхваты, проверочные вопросы и задания, и т. п. Техническая литература — это литература, относящаяся к области техники и производства (каталоги изделий, инструкции по эксплуатации, обслуживанию и ремонту, каталоги деталей, патенты и т. п.). Литература по психологии и саморазвитию — это литература, которая даёт советы по развитию способностей и навыков, достижению успеха в личной жизни и работе, выстраиванию отношений с окружающими, воспитанию детей и т.п. Также существуют и другие виды литературы: духовная, религиозная литература, рекламная литература, выделенная в отдельный вид (листовка, брошюра, рекламный проспект и т. д.), и другие виды, а также отраслевые массивы. Литературный текст остаётся самим собой независимо от того, каково его материальное воплощение: рукопись , книга , компьютерный файл на мониторе . Не следует, однако, думать, что эволюция носителей текста никак не влияет на саму литературу. Напротив, состояние литературы в обозримом прошлом полностью определяется цивилизационной революцией, совершённой изобретшим книгопечатание Гутенбергом : до этого воспроизведение любого сколько-нибудь длинного текста требовало значительных затрат времени и сил писца, и это накладывало существенные ограничения на количество и характер текстов, фиксируемых письменно и распространяющихся за пределы непосредственного круга общения автора . На исходе XX века новая цивилизационная революция вызвала к жизни два качественно новых носителя текста: это аудиокнига и компьютерный файл. Вполне возможно, что повсеместное распространение этих носителей в самом скором будущем приведёт к новым серьёзным изменениям в структуре литературного пространства. Список статей, названия которых начинаются с «Литература» \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts_1[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
